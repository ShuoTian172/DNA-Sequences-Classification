{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score, validation_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import pydot\n",
    "import os\n",
    "\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data loading and preprocessing using the Z-score normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  \\\n",
       "0   1   2   1   2   1   2   3   3   3   3   1   2   1   3   4   2   1   2   2   \n",
       "1   3   3   4   2   1   2   2   4   3   2   2   2   1   2   4   4   3   2   1   \n",
       "2   4   1   4   4   4   4   1   1   2   1   4   2   2   1   3   4   2   2   2   \n",
       "3   1   4   1   1   3   3   4   4   3   4   2   3   4   2   2   3   3   3   3   \n",
       "4   3   4   4   3   1   1   4   4   4   1   1   3   4   4   4   3   1   3   1   \n",
       "5   3   2   3   1   2   3   4   3   1   4   3   4   3   3   1   1   3   1   4   \n",
       "6   4   2   1   4   2   4   4   4   2   3   3   4   3   3   2   3   3   3   4   \n",
       "7   3   3   4   3   1   3   4   3   4   1   4   4   3   1   1   4   2   4   3   \n",
       "8   1   3   4   3   3   1   1   4   2   1   1   4   4   4   4   3   4   2   4   \n",
       "9   1   3   1   1   3   1   1   2   1   1   1   3   3   4   3   3   4   1   4   \n",
       "\n",
       "   19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  \\\n",
       "0   2   1   1   2   3   1   4   2   2   1   4   2   2   1   4   2   2   1   2   \n",
       "1   2   1   3   3   1   2   3   3   4   2   1   3   3   1   1   3   1   4   2   \n",
       "2   1   1   1   1   1   3   1   4   3   1   1   3   4   3   3   4   2   1   1   \n",
       "3   4   3   4   2   3   3   4   4   1   2   2   1   1   4   3   1   4   4   4   \n",
       "4   4   4   4   3   4   4   4   3   1   2   2   1   1   4   1   1   3   1   4   \n",
       "5   2   2   1   3   1   4   4   2   1   3   2   4   2   3   2   1   3   3   3   \n",
       "6   2   3   3   4   2   3   4   3   4   2   3   4   2   2   4   3   4   4   3   \n",
       "7   1   3   1   1   2   1   1   1   4   2   1   3   2   3   1   1   2   1   2   \n",
       "8   1   1   4   4   2   3   4   2   1   3   3   3   1   1   2   1   2   2   1   \n",
       "9   2   3   1   2   1   4   2   2   2   3   3   4   4   1   1   1   4   1   3   \n",
       "\n",
       "   38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  \\\n",
       "0   1   1   2   2   1   4   2   3   3   4   3   2   3   4   2   2   2   2   1   \n",
       "1   2   4   2   1   1   1   3   3   3   3   1   4   3   4   4   4   1   3   4   \n",
       "2   2   4   4   1   2   1   1   1   4   1   1   2   1   1   4   2   2   4   4   \n",
       "3   4   4   1   1   4   1   1   4   2   2   1   3   3   4   1   3   3   4   2   \n",
       "4   4   2   3   3   1   1   1   3   2   4   3   1   3   2   1   4   2   1   1   \n",
       "5   3   3   1   2   2   1   3   3   1   1   2   2   2   3   4   2   2   2   2   \n",
       "6   1   4   3   3   4   3   1   4   1   4   4   3   3   4   2   2   1   2   4   \n",
       "7   3   3   4   1   4   2   4   1   4   2   4   2   2   1   1   4   3   3   1   \n",
       "8   1   1   3   1   3   4   3   4   1   2   2   1   3   2   2   2   2   1   1   \n",
       "9   2   2   3   4   2   2   4   2   2   1   2   4   2   2   2   1   1   3   1   \n",
       "\n",
       "   57  \n",
       "0   1  \n",
       "1   1  \n",
       "2   1  \n",
       "3  -1  \n",
       "4  -1  \n",
       "5  -1  \n",
       "6   1  \n",
       "7   1  \n",
       "8   1  \n",
       "9   1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataB = pd.read_csv('DataDNA.csv', sep = ',', header= None)\n",
    "df2 = pd.DataFrame(dataB)\n",
    "print(df2.shape)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(2200, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  \\\n",
       "0   1   2   1   2   1   2   3   3   3   3   1   2   1   3   4   2   1   2   2   \n",
       "1   3   3   4   2   1   2   2   4   3   2   2   2   1   2   4   4   3   2   1   \n",
       "2   4   1   4   4   4   4   1   1   2   1   4   2   2   1   3   4   2   2   2   \n",
       "3   1   4   1   1   3   3   4   4   3   4   2   3   4   2   2   3   3   3   3   \n",
       "4   3   4   4   3   1   1   4   4   4   1   1   3   4   4   4   3   1   3   1   \n",
       "\n",
       "   19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  \\\n",
       "0   2   1   1   2   3   1   4   2   2   1   4   2   2   1   4   2   2   1   2   \n",
       "1   2   1   3   3   1   2   3   3   4   2   1   3   3   1   1   3   1   4   2   \n",
       "2   1   1   1   1   1   3   1   4   3   1   1   3   4   3   3   4   2   1   1   \n",
       "3   4   3   4   2   3   3   4   4   1   2   2   1   1   4   3   1   4   4   4   \n",
       "4   4   4   4   3   4   4   4   3   1   2   2   1   1   4   1   1   3   1   4   \n",
       "\n",
       "   38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  \\\n",
       "0   1   1   2   2   1   4   2   3   3   4   3   2   3   4   2   2   2   2   1   \n",
       "1   2   4   2   1   1   1   3   3   3   3   1   4   3   4   4   4   1   3   4   \n",
       "2   2   4   4   1   2   1   1   1   4   1   1   2   1   1   4   2   2   4   4   \n",
       "3   4   4   1   1   4   1   1   4   2   2   1   3   3   4   1   3   3   4   2   \n",
       "4   4   2   3   3   1   1   1   3   2   4   3   1   3   2   1   4   2   1   1   \n",
       "\n",
       "   57  \n",
       "0   1  \n",
       "1   1  \n",
       "2   1  \n",
       "3  -1  \n",
       "4  -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df2.isnull().sum().sum())\n",
    "# df2.iloc[:,:-1].head()\n",
    "print(df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1137\n",
       "-1    1063\n",
       "Name: 57, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[57].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[57] = df2[57].map({1: 1, -1: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3   -1\n",
       "4   -1\n",
       "Name: 57, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[57].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calkulas/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/calkulas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.352898</td>\n",
       "      <td>-0.487479</td>\n",
       "      <td>-1.372441</td>\n",
       "      <td>-0.470994</td>\n",
       "      <td>-1.431156</td>\n",
       "      <td>-0.448281</td>\n",
       "      <td>0.405564</td>\n",
       "      <td>0.415676</td>\n",
       "      <td>0.396645</td>\n",
       "      <td>0.392611</td>\n",
       "      <td>-1.454242</td>\n",
       "      <td>-0.500168</td>\n",
       "      <td>-1.369434</td>\n",
       "      <td>0.381451</td>\n",
       "      <td>1.253160</td>\n",
       "      <td>-0.579766</td>\n",
       "      <td>-1.471189</td>\n",
       "      <td>-0.599369</td>\n",
       "      <td>-0.583351</td>\n",
       "      <td>-0.598913</td>\n",
       "      <td>-1.437523</td>\n",
       "      <td>-1.477642</td>\n",
       "      <td>-0.611451</td>\n",
       "      <td>0.332324</td>\n",
       "      <td>-1.495711</td>\n",
       "      <td>1.418861</td>\n",
       "      <td>-0.570943</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>-1.448819</td>\n",
       "      <td>1.821169</td>\n",
       "      <td>-0.776737</td>\n",
       "      <td>-0.237862</td>\n",
       "      <td>-1.131068</td>\n",
       "      <td>1.535688</td>\n",
       "      <td>-0.569710</td>\n",
       "      <td>-0.376354</td>\n",
       "      <td>-1.395430</td>\n",
       "      <td>-0.483853</td>\n",
       "      <td>-1.401924</td>\n",
       "      <td>-1.399702</td>\n",
       "      <td>-0.496609</td>\n",
       "      <td>-0.455196</td>\n",
       "      <td>-1.402111</td>\n",
       "      <td>1.391803</td>\n",
       "      <td>-0.432450</td>\n",
       "      <td>0.472744</td>\n",
       "      <td>0.497988</td>\n",
       "      <td>1.424712</td>\n",
       "      <td>0.453914</td>\n",
       "      <td>-0.464630</td>\n",
       "      <td>0.513026</td>\n",
       "      <td>1.383572</td>\n",
       "      <td>-0.452656</td>\n",
       "      <td>-0.400135</td>\n",
       "      <td>-0.458416</td>\n",
       "      <td>-0.417566</td>\n",
       "      <td>-1.392249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.459203</td>\n",
       "      <td>0.433082</td>\n",
       "      <td>1.360021</td>\n",
       "      <td>-0.470994</td>\n",
       "      <td>-1.431156</td>\n",
       "      <td>-0.448281</td>\n",
       "      <td>-0.495689</td>\n",
       "      <td>1.322008</td>\n",
       "      <td>0.396645</td>\n",
       "      <td>-0.509943</td>\n",
       "      <td>-0.530114</td>\n",
       "      <td>-0.500168</td>\n",
       "      <td>-1.369434</td>\n",
       "      <td>-0.549950</td>\n",
       "      <td>1.253160</td>\n",
       "      <td>1.232002</td>\n",
       "      <td>0.325434</td>\n",
       "      <td>-0.599369</td>\n",
       "      <td>-1.475822</td>\n",
       "      <td>-0.598913</td>\n",
       "      <td>-1.437523</td>\n",
       "      <td>0.346607</td>\n",
       "      <td>0.307396</td>\n",
       "      <td>-1.488629</td>\n",
       "      <td>-0.600319</td>\n",
       "      <td>0.496979</td>\n",
       "      <td>0.392304</td>\n",
       "      <td>1.749605</td>\n",
       "      <td>-0.318134</td>\n",
       "      <td>-1.360333</td>\n",
       "      <td>0.082831</td>\n",
       "      <td>0.675396</td>\n",
       "      <td>-1.131068</td>\n",
       "      <td>-1.391967</td>\n",
       "      <td>0.324910</td>\n",
       "      <td>-1.292259</td>\n",
       "      <td>1.360356</td>\n",
       "      <td>-0.483853</td>\n",
       "      <td>-0.477671</td>\n",
       "      <td>1.376149</td>\n",
       "      <td>-0.496609</td>\n",
       "      <td>-1.391112</td>\n",
       "      <td>-1.402111</td>\n",
       "      <td>-1.357643</td>\n",
       "      <td>0.493928</td>\n",
       "      <td>0.472744</td>\n",
       "      <td>0.497988</td>\n",
       "      <td>0.490475</td>\n",
       "      <td>-1.356803</td>\n",
       "      <td>1.404083</td>\n",
       "      <td>0.513026</td>\n",
       "      <td>1.383572</td>\n",
       "      <td>1.424521</td>\n",
       "      <td>1.435731</td>\n",
       "      <td>-1.374415</td>\n",
       "      <td>0.497419</td>\n",
       "      <td>1.369651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.365253</td>\n",
       "      <td>-1.408039</td>\n",
       "      <td>1.360021</td>\n",
       "      <td>1.317075</td>\n",
       "      <td>1.342890</td>\n",
       "      <td>1.371309</td>\n",
       "      <td>-1.396943</td>\n",
       "      <td>-1.396986</td>\n",
       "      <td>-0.491065</td>\n",
       "      <td>-1.412496</td>\n",
       "      <td>1.318143</td>\n",
       "      <td>-0.500168</td>\n",
       "      <td>-0.476237</td>\n",
       "      <td>-1.481351</td>\n",
       "      <td>0.343575</td>\n",
       "      <td>1.232002</td>\n",
       "      <td>-0.572878</td>\n",
       "      <td>-0.599369</td>\n",
       "      <td>-0.583351</td>\n",
       "      <td>-1.505108</td>\n",
       "      <td>-1.437523</td>\n",
       "      <td>-1.477642</td>\n",
       "      <td>-1.530297</td>\n",
       "      <td>-1.488629</td>\n",
       "      <td>0.295072</td>\n",
       "      <td>-1.346787</td>\n",
       "      <td>1.355552</td>\n",
       "      <td>0.882684</td>\n",
       "      <td>-1.448819</td>\n",
       "      <td>-1.360333</td>\n",
       "      <td>0.082831</td>\n",
       "      <td>1.588655</td>\n",
       "      <td>0.627483</td>\n",
       "      <td>0.559803</td>\n",
       "      <td>1.219529</td>\n",
       "      <td>-0.376354</td>\n",
       "      <td>-1.395430</td>\n",
       "      <td>-1.404680</td>\n",
       "      <td>-0.477671</td>\n",
       "      <td>1.376149</td>\n",
       "      <td>1.367795</td>\n",
       "      <td>-1.391112</td>\n",
       "      <td>-0.485426</td>\n",
       "      <td>-1.357643</td>\n",
       "      <td>-1.358828</td>\n",
       "      <td>-1.361537</td>\n",
       "      <td>1.414020</td>\n",
       "      <td>-1.378000</td>\n",
       "      <td>-1.356803</td>\n",
       "      <td>-0.464630</td>\n",
       "      <td>-1.316240</td>\n",
       "      <td>-1.376046</td>\n",
       "      <td>1.424521</td>\n",
       "      <td>-0.400135</td>\n",
       "      <td>-0.458416</td>\n",
       "      <td>1.412405</td>\n",
       "      <td>1.369651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.352898</td>\n",
       "      <td>1.353642</td>\n",
       "      <td>-1.372441</td>\n",
       "      <td>-1.365028</td>\n",
       "      <td>0.418208</td>\n",
       "      <td>0.461514</td>\n",
       "      <td>1.306817</td>\n",
       "      <td>1.322008</td>\n",
       "      <td>0.396645</td>\n",
       "      <td>1.295164</td>\n",
       "      <td>-0.530114</td>\n",
       "      <td>0.400298</td>\n",
       "      <td>1.310158</td>\n",
       "      <td>-0.549950</td>\n",
       "      <td>-0.566010</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>0.325434</td>\n",
       "      <td>0.311904</td>\n",
       "      <td>0.309119</td>\n",
       "      <td>1.213478</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>1.258732</td>\n",
       "      <td>-0.611451</td>\n",
       "      <td>0.332324</td>\n",
       "      <td>0.295072</td>\n",
       "      <td>1.418861</td>\n",
       "      <td>1.355552</td>\n",
       "      <td>-0.851159</td>\n",
       "      <td>-0.318134</td>\n",
       "      <td>-0.299832</td>\n",
       "      <td>-1.636305</td>\n",
       "      <td>-1.151121</td>\n",
       "      <td>1.506759</td>\n",
       "      <td>0.559803</td>\n",
       "      <td>-1.464329</td>\n",
       "      <td>1.455456</td>\n",
       "      <td>1.360356</td>\n",
       "      <td>1.357802</td>\n",
       "      <td>1.370835</td>\n",
       "      <td>1.376149</td>\n",
       "      <td>-1.428812</td>\n",
       "      <td>-1.391112</td>\n",
       "      <td>1.347943</td>\n",
       "      <td>-1.357643</td>\n",
       "      <td>-1.358828</td>\n",
       "      <td>1.389885</td>\n",
       "      <td>-0.418044</td>\n",
       "      <td>-0.443763</td>\n",
       "      <td>-1.356803</td>\n",
       "      <td>0.469726</td>\n",
       "      <td>0.513026</td>\n",
       "      <td>1.383572</td>\n",
       "      <td>-1.391244</td>\n",
       "      <td>0.517798</td>\n",
       "      <td>0.457583</td>\n",
       "      <td>1.412405</td>\n",
       "      <td>-0.471615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.459203</td>\n",
       "      <td>1.353642</td>\n",
       "      <td>1.360021</td>\n",
       "      <td>0.423041</td>\n",
       "      <td>-1.431156</td>\n",
       "      <td>-1.358075</td>\n",
       "      <td>1.306817</td>\n",
       "      <td>1.322008</td>\n",
       "      <td>1.284354</td>\n",
       "      <td>-1.412496</td>\n",
       "      <td>-1.454242</td>\n",
       "      <td>0.400298</td>\n",
       "      <td>1.310158</td>\n",
       "      <td>1.312852</td>\n",
       "      <td>1.253160</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-1.471189</td>\n",
       "      <td>0.311904</td>\n",
       "      <td>-1.475822</td>\n",
       "      <td>1.213478</td>\n",
       "      <td>1.265512</td>\n",
       "      <td>1.258732</td>\n",
       "      <td>0.307396</td>\n",
       "      <td>1.242800</td>\n",
       "      <td>1.190464</td>\n",
       "      <td>1.418861</td>\n",
       "      <td>0.392304</td>\n",
       "      <td>-0.851159</td>\n",
       "      <td>-0.318134</td>\n",
       "      <td>-0.299832</td>\n",
       "      <td>-1.636305</td>\n",
       "      <td>-1.151121</td>\n",
       "      <td>1.506759</td>\n",
       "      <td>-1.391967</td>\n",
       "      <td>-1.464329</td>\n",
       "      <td>0.539551</td>\n",
       "      <td>-1.395430</td>\n",
       "      <td>1.357802</td>\n",
       "      <td>1.370835</td>\n",
       "      <td>-0.474418</td>\n",
       "      <td>0.435593</td>\n",
       "      <td>0.480721</td>\n",
       "      <td>-1.402111</td>\n",
       "      <td>-1.357643</td>\n",
       "      <td>-1.358828</td>\n",
       "      <td>0.472744</td>\n",
       "      <td>-0.418044</td>\n",
       "      <td>1.424712</td>\n",
       "      <td>0.453914</td>\n",
       "      <td>-1.398986</td>\n",
       "      <td>0.513026</td>\n",
       "      <td>-0.456173</td>\n",
       "      <td>-1.391244</td>\n",
       "      <td>1.435731</td>\n",
       "      <td>-0.458416</td>\n",
       "      <td>-1.332552</td>\n",
       "      <td>-1.392249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.352898 -0.487479 -1.372441 -0.470994 -1.431156 -0.448281  0.405564   \n",
       "1  0.459203  0.433082  1.360021 -0.470994 -1.431156 -0.448281 -0.495689   \n",
       "2  1.365253 -1.408039  1.360021  1.317075  1.342890  1.371309 -1.396943   \n",
       "3 -1.352898  1.353642 -1.372441 -1.365028  0.418208  0.461514  1.306817   \n",
       "4  0.459203  1.353642  1.360021  0.423041 -1.431156 -1.358075  1.306817   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.415676  0.396645  0.392611 -1.454242 -0.500168 -1.369434  0.381451   \n",
       "1  1.322008  0.396645 -0.509943 -0.530114 -0.500168 -1.369434 -0.549950   \n",
       "2 -1.396986 -0.491065 -1.412496  1.318143 -0.500168 -0.476237 -1.481351   \n",
       "3  1.322008  0.396645  1.295164 -0.530114  0.400298  1.310158 -0.549950   \n",
       "4  1.322008  1.284354 -1.412496 -1.454242  0.400298  1.310158  1.312852   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0  1.253160 -0.579766 -1.471189 -0.599369 -0.583351 -0.598913 -1.437523   \n",
       "1  1.253160  1.232002  0.325434 -0.599369 -1.475822 -0.598913 -1.437523   \n",
       "2  0.343575  1.232002 -0.572878 -0.599369 -0.583351 -1.505108 -1.437523   \n",
       "3 -0.566010  0.326118  0.325434  0.311904  0.309119  1.213478  0.364500   \n",
       "4  1.253160  0.326118 -1.471189  0.311904 -1.475822  1.213478  1.265512   \n",
       "\n",
       "         21        22        23        24        25        26        27  \\\n",
       "0 -1.477642 -0.611451  0.332324 -1.495711  1.418861 -0.570943  0.015762   \n",
       "1  0.346607  0.307396 -1.488629 -0.600319  0.496979  0.392304  1.749605   \n",
       "2 -1.477642 -1.530297 -1.488629  0.295072 -1.346787  1.355552  0.882684   \n",
       "3  1.258732 -0.611451  0.332324  0.295072  1.418861  1.355552 -0.851159   \n",
       "4  1.258732  0.307396  1.242800  1.190464  1.418861  0.392304 -0.851159   \n",
       "\n",
       "         28        29        30        31        32        33        34  \\\n",
       "0 -1.448819  1.821169 -0.776737 -0.237862 -1.131068  1.535688 -0.569710   \n",
       "1 -0.318134 -1.360333  0.082831  0.675396 -1.131068 -1.391967  0.324910   \n",
       "2 -1.448819 -1.360333  0.082831  1.588655  0.627483  0.559803  1.219529   \n",
       "3 -0.318134 -0.299832 -1.636305 -1.151121  1.506759  0.559803 -1.464329   \n",
       "4 -0.318134 -0.299832 -1.636305 -1.151121  1.506759 -1.391967 -1.464329   \n",
       "\n",
       "         35        36        37        38        39        40        41  \\\n",
       "0 -0.376354 -1.395430 -0.483853 -1.401924 -1.399702 -0.496609 -0.455196   \n",
       "1 -1.292259  1.360356 -0.483853 -0.477671  1.376149 -0.496609 -1.391112   \n",
       "2 -0.376354 -1.395430 -1.404680 -0.477671  1.376149  1.367795 -1.391112   \n",
       "3  1.455456  1.360356  1.357802  1.370835  1.376149 -1.428812 -1.391112   \n",
       "4  0.539551 -1.395430  1.357802  1.370835 -0.474418  0.435593  0.480721   \n",
       "\n",
       "         42        43        44        45        46        47        48  \\\n",
       "0 -1.402111  1.391803 -0.432450  0.472744  0.497988  1.424712  0.453914   \n",
       "1 -1.402111 -1.357643  0.493928  0.472744  0.497988  0.490475 -1.356803   \n",
       "2 -0.485426 -1.357643 -1.358828 -1.361537  1.414020 -1.378000 -1.356803   \n",
       "3  1.347943 -1.357643 -1.358828  1.389885 -0.418044 -0.443763 -1.356803   \n",
       "4 -1.402111 -1.357643 -1.358828  0.472744 -0.418044  1.424712  0.453914   \n",
       "\n",
       "         49        50        51        52        53        54        55  \\\n",
       "0 -0.464630  0.513026  1.383572 -0.452656 -0.400135 -0.458416 -0.417566   \n",
       "1  1.404083  0.513026  1.383572  1.424521  1.435731 -1.374415  0.497419   \n",
       "2 -0.464630 -1.316240 -1.376046  1.424521 -0.400135 -0.458416  1.412405   \n",
       "3  0.469726  0.513026  1.383572 -1.391244  0.517798  0.457583  1.412405   \n",
       "4 -1.398986  0.513026 -0.456173 -1.391244  1.435731 -0.458416 -1.332552   \n",
       "\n",
       "         56  \n",
       "0 -1.392249  \n",
       "1  1.369651  \n",
       "2  1.369651  \n",
       "3 -0.471615  \n",
       "4 -1.392249  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Z-score normalized values\n",
    "normalized_df = df2.iloc[:,:-1]\n",
    "std_scale = preprocessing.StandardScaler().fit(normalized_df)\n",
    "df_std = std_scale.transform(normalized_df)\n",
    "df_zscore = pd.DataFrame(df_std)\n",
    "df_zscore.columns =  normalized_df.columns\n",
    "df_zscore.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Parameter Selection: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 1, Accuracies: [-0.30097087 -0.30519481 -0.30844156 -0.27922078 -0.27687296]\n",
      "For k= 3, Accuracies: [-0.22258181 -0.19444444 -0.20310245 -0.19083694 -0.19471589]\n",
      "For k= 5, Accuracies: [-0.18640777 -0.17012987 -0.17948052 -0.1838961  -0.1904886 ]\n",
      "For k= 7, Accuracies: [-0.17845585 -0.17373443 -0.18274583 -0.17691492 -0.18586718]\n",
      "For k= 9, Accuracies: [-0.17711455 -0.1675485  -0.17805034 -0.17756934 -0.18156593]\n",
      "For k= 11, Accuracies: [-0.17288507 -0.16818718 -0.17792744 -0.17599549 -0.18424099]\n",
      "For k= 13, Accuracies: [-0.17424025 -0.16541151 -0.17707293 -0.173538   -0.18229478]\n",
      "For k= 15, Accuracies: [-0.17386552 -0.16686869 -0.17647908 -0.17252525 -0.18136808]\n",
      "For k= 17, Accuracies: [-0.1758323  -0.16625848 -0.17807711 -0.17179706 -0.18041545]\n",
      "For k= 19, Accuracies: [-0.1769357  -0.16627694 -0.17812174 -0.17415548 -0.18152616]\n",
      "For k= 21, Accuracies: [-0.17748718 -0.16687281 -0.17966104 -0.1724534  -0.18297178]\n",
      "For k= 23, Accuracies: [-0.18156625 -0.1666278  -0.18145607 -0.17121253 -0.17904842]\n",
      "For k= 25, Accuracies: [-0.18353398 -0.16444675 -0.18195325 -0.17302857 -0.1804873 ]\n",
      "For k= 27, Accuracies: [-0.18566463 -0.16768657 -0.18137726 -0.17341849 -0.18141401]\n",
      "For k= 29, Accuracies: [-0.18605528 -0.17007814 -0.18147073 -0.17436339 -0.18142664]\n",
      "For k= 31, Accuracies: [-0.18503851 -0.16945619 -0.18262903 -0.1757774  -0.18382724]\n",
      "\n",
      "\n",
      "Mean of accuracy scores: [-0.29414019616258635, -0.20113630640337576, -0.18208057196906383, -0.17954364107192022, -0.1763697335423579, -0.175847236587732, -0.17451149318238618, -0.17422132201006998, -0.1744760808231834, -0.1754032038677153, -0.17588924037619008, -0.17598221106803885, -0.17668996968560674, -0.17791219184772697, -0.1786788357340912, -0.17934567345566949]\n",
      "\n",
      "\n",
      "Length of list 16\n",
      "Max of list -0.17422132201006998\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df_zscore.loc[:,]\n",
    "y = df2[57]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30,random_state=42)\n",
    "\n",
    "# 5-fold cross-validation with k = [1, 3, 5, 7, 31] for KNN (the n_neighbors parameter)\n",
    "k = list(range(1,32,2))\n",
    "k_scores = []\n",
    "\n",
    "for i in k:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='brier_score_loss')\n",
    "    k_scores.append(scores.mean())\n",
    "    print(\"For k= {}, Accuracies: {}\".format(i, scores))\n",
    "    \n",
    "\n",
    "print('\\n')\n",
    "print('Mean of accuracy scores:', k_scores)\n",
    "print('\\n')\n",
    "print('Length of list', len(k_scores))\n",
    "print('Max of list', max(k_scores))\n",
    "\n",
    "plt.plot(k, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-validated accuracy')\n",
    "# plt.title('')\n",
    "plt.savefig(os.path.join('2-2-a-kNN.png'), dpi=300, format='png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "#ref: https://www.ritchieng.com/machine-learning-cross-validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) SVM (RBF Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "param_grid = {'C': [0.1, 0.5, 1, 2, 5,10, 20, 50], 'gamma': [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]}\n",
    "grid = GridSearchCV(SVC(kernel='rbf'),param_grid,cv=5,refit=True, scoring='roc_auc')\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM GATHER DATA\n",
    "rbf_svc = SVC(kernel='rbf', gamma=0.01, C=10,probability=True).fit(X_train,y_train)\n",
    "\n",
    "#PREDICT PROBABILITY SCORE = 2D ARRAY FOR EACH PREDICTION\n",
    "predictedprobSVC = rbf_svc.predict_proba(X_test)\n",
    "\n",
    "#GET ROC DATA\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictedprobSVC[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#GRAPH DATA\n",
    "plt.figure()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "#plt.xlim([0.0, 1.0]\n",
    "#plt.ylim([0.0, 1.05])\n",
    "plt.title('SVM Classifier ROC')\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='SVM ROC area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(os.path.join('2-2-b-svm.png'), dpi=300, format='png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#ref :https://medium.com/datadriveninvestor/computing-an-roc-graph-with-python-a3aa20b9a3fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training classifiers and reporting the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Classifying the test set using k-NN, SVM, Random Forests, and Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_zscore.loc[:,]\n",
    "y = df2[57]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knn and SVM with chosen parameters from part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "svm = SVC(kernel='rbf', gamma=0.01, C=10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(X_test)\n",
    "svm_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k-NN:\n",
      "Accuracy is  75.75757575757575\n",
      "[[313  24]\n",
      " [136 187]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.93      0.80       337\n",
      "           1       0.89      0.58      0.70       323\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       660\n",
      "   macro avg       0.79      0.75      0.75       660\n",
      "weighted avg       0.79      0.76      0.75       660\n",
      "\n",
      "Classification Report for SVM:\n",
      "Accuracy is  90.75757575757576\n",
      "[[310  27]\n",
      " [ 34 289]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.92      0.91       337\n",
      "           1       0.91      0.89      0.90       323\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       660\n",
      "   macro avg       0.91      0.91      0.91       660\n",
      "weighted avg       0.91      0.91      0.91       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for k-NN:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,knn_pred)*100)\n",
    "print(confusion_matrix(y_test,knn_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,knn_pred))\n",
    "\n",
    "print(\"Classification Report for SVM:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,svm_pred)*100)\n",
    "print(confusion_matrix(y_test,svm_pred))\n",
    "print(classification_report(y_test,svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest and Neural Network classifiers with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)\n",
    "nn_mlp = MLPClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "nn_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(X_test)\n",
    "nn_mlp_pred = nn_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Random Forests: \n",
      "Accuracy is  94.6969696969697\n",
      "[[329   8]\n",
      " [ 27 296]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.98      0.95       337\n",
      "           1       0.97      0.92      0.94       323\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       660\n",
      "   macro avg       0.95      0.95      0.95       660\n",
      "weighted avg       0.95      0.95      0.95       660\n",
      "\n",
      "Classification Report for Neural Network:\n",
      "Accuracy is  90.45454545454545\n",
      "[[308  29]\n",
      " [ 34 289]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.91      0.91       337\n",
      "           1       0.91      0.89      0.90       323\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       660\n",
      "   macro avg       0.90      0.90      0.90       660\n",
      "weighted avg       0.90      0.90      0.90       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Random Forests: \")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,rfc_pred)*100)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,rfc_pred))\n",
    "\n",
    "print(\"Classification Report for Neural Network:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,nn_mlp_pred)*100)\n",
    "print(confusion_matrix(y_test,nn_mlp_pred))\n",
    "print(classification_report(y_test,nn_mlp_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Exploring parameters for Random Forest and Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9463348981635447"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, rfc_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for estimator in n_estimators:\n",
    "   rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1, random_state=42)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "\n",
    "    \n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.title('AUC plot for RF')\n",
    "plt.savefig(os.path.join('2-3-b-rf(n_estimator).png'), dpi=300, format='png', bbox_inches='tight')\n",
    "plt.show()\n",
    "# Source: https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEXCAYAAACDChKsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XlcVPX6wPHPDAMIArLIAO6aGWVwNb39xAXFcglBrTDNhUql23KzzBbLpa6lpbei8na9NyttEXNLlFQitazUW2kp7opF7jAwyL7MzDm/P8hJFGSJYQZ43q+XrzjLnHmeOffOM99zzvf71aiqqiKEEELUktbeAQghhGicpIAIIYSoEykgQggh6kQKiBBCiDqRAiKEEKJOpIAIIYSoEykgokkxmUz079+fqVOnVlh/ww03YDQaK6xLTk5m0qRJ1uW8vDxefvlloqOjGTVqFKNHj2bNmjW1jmHw4MEcOHDgmvukpqYyd+7cSrd99913REREEBMTQ0lJSa3fH+D7778nNDSUUaNGWf/dfvvtPPTQQ+Tk5ACwePFi+vTpU2GfUaNGVRu7EJfo7B2AEPXpyy+/JDg4mIMHD3Ly5Emuu+66Gr2utLSUiRMnEh0dzfr169HpdJw9e5b7778fgDFjxtRrnGlpaWRkZFS6bdOmTYwZM4ZHHnnkT71Hhw4d2LBhg3XZYrHw2GOP8cEHHzBjxgwAIiMjqyxkQlRHCohoUlauXElkZCQdOnTgww8/ZN68eTV63ebNm3F3dycuLs66rm3btrz55puYTKar9l+8eDG//fYbFy5cwGAwEBwczPz58/Hw8Kiw36pVq/j444/RarW0bt2aOXPm0KJFC95++23y8/N57rnneOWVV6z7v/fee2zbtg1XV1fy8/N58sknefXVV9m9ezdOTk6Ehoby3HPP4eHhweDBgwkNDeXYsWM8+eSTDBky5Jo5FhQUYDQaueWWW2r0mQhRHSkgoslIS0vj559/5u2336Z79+5MmjSJ6dOn4+PjU+1rDx48WOkXa/fu3at8zY8//si6devw9fXl6aef5p133uHZZ5+1bt+9ezfvvfceq1atwtfXl88++4xHH32UTZs2MW3aNL744osKxQNg6tSppKWlcf311zNlyhTefvttMjMz2bBhA05OTsyaNYtFixZZC+P111/Pm2++WWl8p06dYtSoUZjNZoxGI4GBgdxxxx3cd9991n02b97M3r17rctDhgzh73//e7WflxAg90BEE7Jy5UoiIiLw8fEhNDSUdu3asXr1agA0Gs1V+yuKglartW6v7ag+w4cPp3Xr1mi1WmJiYvjuu+8qbP/222+JjIzE19cXgLvuuouMjAzOnDlT4/f45ptvGDduHM7Ozmi1WiZNmsS3335r3d67d+8qX3vpEtamTZt46qmnMBgM3HHHHTg7O1v3iYyMZMOGDdZ/UjxEbUgBEU1CUVERGzZsYO/evQwePJjBgwdjMBj45JNPMJlM+Pj4cPHixQqvyc7OxtvbG4AePXqwb9++q467bds2Fi5cWOl7Ojk5Wf++vBhdvu5KqqpiNptrnJeiKBWKn6IoFS6pubu71+g4d999N4MHD+bxxx+v1fsLcS1SQESTkJSUhLe3N99++y3bt29n+/btbN26laKiIpKTkwkPD+fjjz+2fqnn5uayfv16Bg4cCMDQoUMpKChg6dKlWCwWAE6fPs2rr75a5Y34bdu2kZ+fj6IorF69moiIiArbBwwYwObNm61Pf61btw5vb286duyIk5NTjb7IBwwYwMqVKzGZTCiKwooVK+jXr1+dPqOnnnqK8+fPs2LFijq9XogrSQERTcLKlSt54IEHKrQKvLy8mDRpEsuXL2fWrFmUlpYSFRVFdHQ0EydOJDIykjvvvBMAFxcXli1bRlpaGtHR0URHR/PYY4/x8MMPExMTU+l7tm7dmri4OO644w48PT156KGHKmzv168f999/P/fddx8jRowgMTGR//73v2i1Wnr06MHp06ervWT08MMP07p1a0aPHs0dd9yB2Wxm1qxZdfqMvLy8eOqpp1i8eDFZWVl1OoYQl9PIcO5C1N7ixYvJycmRR2BFsyYtECGEEHUiLRAhhBB1Ii0QIYQQdSIFRAghRJ1IARFCCFEnUkCEEELUSZMcCysnpxBFqfhsgJ+fB9nZBXaKqH5IDo5BcnAMkkP90Wo1+Pi0rPXrmmQBURT1qgJyaX1jJzk4BsnBMUgO9iWXsIQQQtSJFBAhhBB1IgVECCFEndi8gBQUFBAVFVXpHAhHjhzhrrvuYtiwYcyaNcs6Oum5c+eYMGECw4cP5+GHH6awsNDWYQohhKglmxaQ/fv3c++995Kenl7p9qeffpq5c+fyxRdfoKqqdfKff/zjH4wfP57k5GRuvvlm/v3vf9syTCGEEHVg06ewVq9ezQsvvMAzzzxz1bazZ89SUlJCjx49gPLZ2t5++23GjBnDjz/+yDvvvGNdP3HiRJ5++mlbhioagKKoFJWYKC5t3BMaSQ6OQXK4mquLE9pKZt+0FZsWkPnz51e5LTMzE39/f+uyv78/GRkZ5OTk4OHhgU6nq7BeND4WReFURgHHTl3k6KkcTpzJbfT/hxfCkQ3q0YbY4cEN9n526wdy5VSdqqpa56W+cv7qyuazvhY/P49K1/v7e9Y+UAfjyDmYLQppZy5y8GQ2B05mceRXo7VgtPX3ILxnW9r6e9CAP5CEaFb+cr1/g35H2K2ABAYGYjAYrMtZWVno9Xp8fX3Jz8/HYrHg5OSEwWBAr9fX6tjZ2QVXdc7x9/fEYMivl9jtxZ45KIpKQbGJ/KIy8otM5F/+d1EZGcYi0s7mUWoqnw62TeuW9LkpgBs6eNOtvTfeHq52z6G+SA6OQXKoXF2Op9VqqvzhfS12KyBt27bF1dWVvXv30qtXLzZs2EB4eDjOzs707t2bzZs3Ex0dTWJiIuHh4fYKs9lSVZXvUs+Tsuc0uQVlFBabqKq/bMsWOny9WtA/JMhaMLxaujRovEKIhtfgBSQuLo5p06YREhLCa6+9xuzZsykoKKB79+7ExsYC8MILLzBz5kyWLFlCUFAQb7zxRkOH2axl5RbzYfIxDv1qpHOQJ72D9Xi6OePp7oynu4v1v17uzrR0c0bnJN2JhGiOmuSMhHIJq24UVWXHz2dZ/fVJUGFMxHUM6tm2Xp/qkPPgGCQHx+AoOTS6S1jCsWTmFLF8y1GOnrpI904+3Dc8mNbebvYOSwjhwKSANHOKorJt7xnWfXMSJ62G++8IZkBoUK2ffBNCND9SQJqx89mFLNt8lLSzuYRe50fssBvw9Wph77CEEI2EFJBmSFVVvvjhNJ998wuuzlqmRt1IWPdAaXUIIWpFCkgz9L9DGaz+Ko2e17cmdtgNtPq9j4YQQtSGFJBmprjUzOqv0ugc5MWjd4U06Lg5QoimRR7gb2Y27vyVvMIyJg7tJsVDCPGnSAFpRs5mFbJ1zxkG/KUNnYO87B2OEKKRkwLSTKiqSsKXx2nh4sTdA7vYOxwhRBMgBaSZ2HvMwJHfcrgzvAue7jJOlRDiz5MC0gyUlln4dPsJOug9GNSjrb3DEUI0EVJAmoFN/0vHmFfK+CHd0GrlxrkQon5IAWniMnKKSP7+FGHdA+jW3tve4QghmhApIE3cp1tP4OSkZUxEV3uHIoRoYqSANGH70rLYfzKbUf06W2cEFEKI+iIFpIkymS18uvUEQX7u3N67nb3DEUI0QVJAmqjkH06TebGY8UO6yYyBQgibsOk3S1JSEpGRkQwdOpQVK1ZctX3Hjh1ER0cTHR3NjBkzKCwsBCA3N5e4uDhGjhxJTEwMR44csWWYTU52bgmbdqXT+wZ/unfytXc4QogmymYFJCMjg/j4eBISEkhMTGTVqlWkpaVZt+fl5TFz5kzi4+NJSkoiODiY+Ph4AJYtW0a3bt3YuHEjjzzyCPPmzbNVmE3Squ0nABg7+Ho7RyKEaMpsVkB27dpFnz598Pb2xt3dnWHDhpGcnGzdnp6eTps2bejatfzpoIiICLZu3QqAoijW1khxcTEtWsgkRzV1KN3InmMGRoR1xK+VfG5CCNux2XDumZmZ+Pv7W5f1ej2pqanW5U6dOnHhwgWOHj1KcHAwW7ZsISsrC4DJkyczduxY+vfvT2FhIR988IGtwmxSikvNrEg5jr93C4b/Xwd7hyOEaOJsVkAURakww52qqhWWvby8WLhwIXPmzEFRFO655x6cnZ0BeOmll5gwYQKxsbH8/PPPTJ8+nU2bNtGyZcsavbefn0el6/39Pf9ERo6hqhwsFoV5H3xP5sVi5sWF0SbIcTsNNuXz0JhIDo6hMedgswISGBjInj17rMsGgwG9Xm9dtlgsBAYGsmbNGgBSU1Np3749ANu2bbPe9+jZsyd+fn6cPHmS0NDQGr13dnYBiqJWWOfv74nBkP+ncrK3qnJQVZWPvjjGT0cziR1+A218Wjhsrk35PDQmkoNjcJQctFpNlT+8r/k6G8QCQN++fdm9ezdGo5Hi4mJSUlIIDw+3btdoNEyePJmMjAxUVWX58uVERkYCEBwcbL0fkp6eTmZmJp07d7ZVqI3elu9PsWPfOSL7dJTBEoUQDcZmLZCAgACmT59ObGwsJpOJmJgYQkNDiYuLY9q0aYSEhDBv3jymTp1KWVkZYWFhTJkyBYBXX32VuXPnsnTpUlxcXFi4cCGeno23mWdL3x/OYO3XJ7n1Rj13yTwfQogGpFFVVa1+t8aluVzCOn76Iq99+jNdgryYMa4nzjrH7zDYFM9DYyQ5OAZHycHhLmEJ2zqfXcjidan4tXLj73eHNoriIYRoWuRbpxHKKyzjzTX70Wo1TL/nL3i4Ods7JCFEMyQFpJEpNVl4e10qFwvKmBYTit7bzd4hCSGaKSkgjYhFUVmadJhfz+XxYHR3rmvTyt4hCSGaMSkgjciypEP8dNzA2Nuup9cN/tW/QAghbEgKSCOx/aczbPjmJLf3asfQv7a3dzhCCCEFpDEoLjWz9uuT3HKDnnG3yQi7QgjHIAWkEfg29TwlZRYm3XEjWq2m+hcIIUQDkALi4BRFZeue01zfrhVd2zvuAIlCiOZHCoiD+/lEFlm5JQzpLfc9hBCORQqIg/tyz2n8vFrQs1tre4cihBAVSAFxYL9dyOf46Yvc3rsdTlo5VUIIxyLfSg7syz2ncXVxYkBoG3uHIoQQV5EC4qAuFpTy/eEM+ocE4d7CZqPuCyFEnUkBcVBf/XQWRVG5vXc7e4cihBCVkgLigExmC1/9fJa/dG1NgI+7vcMRQohKSQFxQP87lEFBsYkhMmSJEMKBSQFxMKqq8uWe07Tz9yC4g3QcFEI4LpsWkKSkJCIjIxk6dCgrVqy4avuOHTuIjo4mOjqaGTNmUFhYCEBBQQEzZsxg9OjRjB49mkOHDtkyTIdy5LcczhgKGfLXdmg0MmyJEMJx2ayAZGRkEB8fT0JCAomJiaxatYq0tDTr9ry8PGbOnEl8fDxJSUkEBwcTHx8PwCuvvEJQUBCJiYk8+eSTvPjii7YK0+F8+eNpvNyd6XNTgL1DEUKIa7JZAdm1axd9+vTB29sbd3d3hg0bRnJysnV7eno6bdq0oWvXrgBERESwdetWVFUlJSWFBx98EIDw8HAWLFhgqzAdSoaxiP0nsxnUsy3OOid7hyOEENdksw4GmZmZ+Pv/MemRXq8nNTXVutypUycuXLjA0aNHCQ4OZsuWLWRlZZGdnY2LiwsJCQl89dVXuLq68vzzz9fqvf38PCpd7+/vWbdkGshn3/6KzklLzO034OPVotJ9HD2HmpAcHIPk4Bgacw42KyCKolS4hq+qaoVlLy8vFi5cyJw5c1AUhXvuuQdnZ2csFgtZWVl4enqyatUqdu7cyaOPPsq2bdtq/N7Z2QUoilphnb+/JwZD/p9PzEaKSkx8+cMp/u9GPeZSEwaD6ap96isHc14exs83oHVvSYuOnXDt2BGdj2+D3HNpyPOgmMrISfmCi9u3oVrM5flpNKDRotFqy//WasrXa7WABmrwEeictJgtis3jtyXJwTHUdw6tBgzEd9gdtX6dVqup8of3tdisgAQGBrJnzx7rssFgQK/XW5ctFguBgYGsWbMGgNTUVNq3b4+Pjw86nY6oqCgA+vXrR1FREdnZ2fj5+dkqXLv7Zv95Sk0Wmz+6a87P48zriyi7cB4UBdTyQuvk6Ylrx06/F5Ty/+p8G6ao1DdVVSn4aS+GNZ9izsrC/eZQnP39rfmq6u95K2r58qXPQa3Z/5FdXZ0pLb26wDcmkoNjqO8cnP0adtBVmxWQvn37snjxYoxGI25ubqSkpPDSSy9Zt2s0GiZPnsyaNWvQ6/UsX76cyMhIXFxc6Nu3L5s2bWL8+PHs27cPNzc3fHx8bBWq3VkUhW17TxPcwZsOAbZrzlry8znz+j8xZWbQ7okZtOhyHaVnTlPyWzql6emU/JaO8fCh8i9awMnDE9eOHXFp0xbXoDa4tCn/5+Te0mYx/lmlp0+TuSqB4qNHcGnbjnYznsH9xpvq9T0cvTVbE5KDY2jsOdisgAQEBDB9+nRiY2MxmUzExMQQGhpKXFwc06ZNIyQkhHnz5jF16lTKysoICwtjypQpAMyfP5+5c+eSkJCATqcjPj4ebRMejfbn41lk55Uy/vZuNnsPS0EBZ95YhOnCedo89oT1S9Xtuq64XdfVup9SVkbp6VOUnvqtvLCcOkXu19tRTX/8SnJq5Y1rmza4WItKW5xb+6N1cUHj4oJGpyu/RNSALAUFZG34jNyvv0Lr7o5+wiRahQ9C4yQPIwhhKxpVVdXqd2tcGts9kAUf7yW3sJRXHgyrcsra7I2JtNCB2+BhaFu41er45cXjn5SdO0ubvz9Oy5tDavV6VVEwZWdRdu5c+b/zZyk9d46y8+dQS0srfY1GpysvJs4uaF2c0Tg7o3F2wd3fD40+CNd27XFp1x6XgIA/9SWvms1c3PEV2RsSUUqK8R4Ugd/IO3HyqP313Jpy5P8t1ZTk4BgcJQeHuwciauaXc3mknc3l3tuur7J4FB09QvbGRACctn+Nftx4PHr9tUb3JyyFhZyJf628eDw6rdbFA0Cj1eLir8fFXw9/6WFdr6oqZqORsvNnMWVno5pMqGVlKL//VzVd+ttU/neZiVKDgaKf94HFUn5sZ+fyS2Tt2+PargOu7drh2q49Wnd3VLMZ1WxCNZlRLeY//msu/2fOMZK9YT1l587hfuNN+I8bj2tbGXxSiIYiBcTOtu09TQsXJ/qHBlW6XTWbyUz4BF3r1gRPn8aJ/77P+f/8G/fuN6MfPwmXgKo7HFqKyotH6ZnTtHn0MVqGhNZr7BqNBmc/P5xr8XCDv78nGeeMlJ0/R9mZM+WXy86coXD/PvK++7bWMTj7+5fn1uOWRnnDX4jGTAqIHRUUm/jxqIHwvwTh5lr5qbi4fZu19dDq5u50mDWXi19tJztxHb+9MAvfEdH4DI9E6+xc4XWW4mLOvvk6padP0ebhv+MR2qPS49uD1tmZFh060qJDR6AfUN6aseTlUnrmDKVnTqOWlZVfBrvqn/Mff7u40KJLF7TOLvZNSIhmSgqIHe08cB6zRWFQj7aVbjfnXiR743rcbw6lZY+eAGicnPC5fQievXtjWLWS7A3ryfvfLvQTYml5U3cAlJLy4lHy22+0eehRPH5/rSPTaDToWnmja+VNy+432zscIUQNNN1Hmxycqqrs2HeO69p60U5f+c0rw9rVqGYz+nvHX3V5RuftQ9DfHqHt9KdAhbNv/JPz7y6hLOMCZ958g5L0Xwn62yN49LylIdIRQjRD0gKxk2OnLnLBWMSUETdWur34xHHyd+/CNzIKl4DAKo/TsvvNdPzHS+Rs2Yxx8+fk//A9aLUE/e1hPG/pZavwhRBCCoi9fL3vLO6uOv4arL9qm2qxkLHiY3S+vviOiK72WFpnF/xGjsbz//qQnbQBz1698egpxUMIYVtSQOwgr6iMvccMRPRsi4vz1X0gLu74irIzpwl6+FG0rq41Pq5LQCBBU/9Wn6EKIUSV5B6IHew8cB6LojKw59U3z815eWSvX4f7jd3xuKW3HaITQoiakQLSwJTfb55f364VbVtfPaZU1ro1KGVl6MdPkH4NQgiHJgWkgR39LYfMnOJKH90tPplG3s5v8RkyDJegNnaITgghak4KSAP7et85WrbQ0TvYv8J6VVHIXPExTt7e+EWNtFN0QghRc1JAGlBuYRk/HzfQLyToqilrc7/5mtJTv+F/zzi0LSqfjVAIIRxJjQpIcnIy8fHxFBcX8/nnn9s6pibru9Rz5TfPe1S8PGXJzyfrs3W4Bd+I51//z07RCSFE7VRbQN59911WrlxJcnIyJSUl/Otf/+Kdd95piNialEs3z4M7eBPkV/Hmedb6dSilJejvnSg3zoUQjUa1BWTTpk0sXbrUOivg6tWrpRVSB4d/NZKVW8LAK26el6T/Su63O/AZfDuubSsfE0sIIRxRtQVEp9Ph4vLHaKdeXl7odNL/sLa+3ncODzdnbulW8ea5YfWnOHl64jtytJ0iE0KIuqm2gAQFBfH111+j0WgoKytjyZIltK3hL+WkpCQiIyMZOnQoK1asuGr7jh07iI6OJjo6mhkzZlBYWFhh+4ULF7j11ls5c+ZMDdNxTDn5pew7kUX/0CCcdX985EVHj1B8/Bi+I6JxcqvdLINCCGFv1RaQOXPmsGzZMo4dO0aPHj345ptvmDt3brUHzsjIID4+noSEBBITE1m1ahVpaWnW7Xl5ecycOZP4+HiSkpIIDg4mPj7eul1RFGbNmoXpsrm4G6vvUs+hqBVvnquqSvbGRJy8vWkVPtCO0QkhRN1UW0AOHDjAhx9+yN69e/nhhx9YuXIlbdpU38lt165d9OnTB29vb9zd3Rk2bBjJycnW7enp6bRp04auXbsCEBERwdatW63b33vvPfr27YuPj09d8nIYiqLyzf5z3NjRhwAfd+v64mNHy1sfkVEyIZIQolGqtoBcahW4ubnh4VHzSdczMzPx9//jer9erycjI8O63KlTJy5cuMDRo0cB2LJlC1lZWQAcPHiQ//3vfzzwwAM1fj9HdfDXbLLzShl02bhXFVofA8LtGJ0QQtRdtXfDu3XrxpIlS+jduzfu7n/8gu7evfs1X6coSoVHUlVVrbDs5eXFwoULmTNnDoqicM899+Ds7ExxcTH/+Mc/eOutt9Bq69bP0c+v8kLn7+9Zp+P9GbuTDuPt4cqQsM7W+x8XUw9QfPwYXR6cQkCbms8nDvbJob5JDo5BcnAMjTmHagvI/v372b9/P2vWrLGu02g0bNu27ZqvCwwMZM+ePdZlg8GAXv/H3BcWi4XAwEDrcVNTU2nfvj179uwhOzubhx9+GChvyTz44IP861//okuXLjVKKju7AEVRK6zz9/fEYMiv0evrizGvhB8OX+CO/+vIxZzyBwRUVeXMRwnofHzQ9vy/WsVkjxzqm+TgGCQHx+AoOWi1mip/eF9LtQVk+/btdQqob9++LF68GKPRiJubGykpKbz00kvW7RqNhsmTJ7NmzRr0ej3Lly8nMjKSAQMGVHjPwYMH8+6779KuXbs6xWFP36aeR1Uh/LKb58VHj1B84jj68RPl3ocQolGr9hpRUVERL774IoMHDyY8PJznnnuOgoKCag8cEBDA9OnTiY2NZfTo0URFRREaGkpcXBwHDhxAq9Uyb948pk6dyvDhw/Hy8mLKlCn1kpQjsCgK3+w/R/fOvui9yx/RvXTvQ+fjg5fc+xBCNHIaVVXVa+0wZ84cLBYLkyZNwmKxkJCQgMViYeHChQ0VY605wiWsfWlZvL02lUfvvJleN5Rfuis6cpgzry9CP34i3oNvr/UxHaW5+2dIDo5BcnAMjpKDzS5h7d+/n40bN1qXX375ZUaMGFHrN2pu9h7LxN1Vx1+6tgak9SGEaHqqvYRlsVhQFMW6rCgKTk5Xz+Mt/qCoKgd/MdK9sy86p/KP+NK9D+n3IYRoKqptgYSFhfHEE09w7733ArBy5UpuvfVWmwfWmJ3OKCC3sIyQLuWP6FZoffSX1ocQommotoDMnDmTJUuW8MYbb2CxWAgPD7c+Yisqd+CXbABCuvgClz15NWESWmdne4YmhBD1pkbD6nbs2JE1a9ZgMBjYtGkTzvIleE0HfsmmQ4AHrTxcL2t9+ErrQwjRpFR7D+TFF1/k66+/Lt9Zq2Xv3r0sWLDA1nE1WkUlJk6ezbNevio6cviyex9SeIUQTUe1LZB9+/ZZJ5Dy8/PjrbfeYtSoUTYPrLE6lJ6DoqqEdPG7ovUxwN6hCSFEvaq2BWIymSgrK7Mum81mmwbU2B04mY27q47r2npRdOQwJWknpPUhhGiSqm2BDBo0iClTpjBq1Cg0Gg2ff/45AwfK/BWVUVWVA79mc1NnX7QaTXnrw1daH0KIpqnaAvLMM8+wYsUKtm3bhk6nY8iQIYwbN64hYmt0TmcWkFtQRkgXX4oOH6Ik7QT6ibHS+hBCNEnVFhAnJydiY2OJjY0lIyOD06dP13mY9abu0uO7N3fywfDGEnStW+PVT1ofQoimqdpKkJCQwIwZMzAajdx1113MmjWL119/vSFia3QOnMymg94Dzb7vKTtzGv+YsdL6EEI0WdUWkLVr1/Lcc8+RnJzM4MGD2bRpEzt37myI2BqVohITaWfz+Ev7lmSvX4fb9d3w6NXb3mEJIYTNVFtANBoNrVu3Zvfu3YSFhaHT6SqMjSXKHf798d3up/diKSjAf+z4CjMwCiFEU1NtAXFxcWHp0qX88MMP9OvXj4SEBNzc3BoitkYl9ZdsAjVF8MM3ePXtT4tOnewdkhBC2FS1BWT+/Pmkp6ezcOFCWrVqxd69e5k/f35DxNZoqKrKwV+yiczfj8bJidZ33m3vkIQQwuaqfQqrS5cuFQqG3EC/2unMArwyT6G/cALf0Xeh8/a2d0hCCGFzNn0eNykpicjISIYOHcqKFSuu2r5jxw6io6OJjo5mxowZFBYWAnDy5EkmTJjAqFGjGDt2LEeOHLFlmH/agTQDt2X9iNbHF5+hw+0djhBCNAibFZCMjAzi4+NJSEggMTFbJJgGAAAgAElEQVSRVatWkZaWZt2el5fHzJkziY+PJykpieDgYOLj4wGYPXs2cXFxbNiwgSeeeIJnn33WVmHWi7xdOwkoyyFgzFi0LjJZlBCiebBZAdm1axd9+vTB29sbd3d3hg0bRnJysnV7eno6bdq0oWvXrgBERESwdetWAMaMGcOAAeUd8G644QbOnz9vqzD/tIKcfG5I20mhfzs8/ioTbQkhmo9rFpB169aRmppqXV60aBHr16+v0YEzMzPx9/e3Luv1ejIyMqzLnTp14sKFCxw9ehSALVu2kJWVBcBdd91lnTb37bff5vbbb69hOg3v1zWf4WEpwX3kGHlsVwjRrFR5E33t2rW8++67vPXWW9Z1vXr1YuHChWg0GkaPHn3NAyuKUuELVVXVCsteXl4sXLiQOXPmoCgK99xzT4WJqlRVZdGiRezfv5+PPvqoVkn5+XlUut7f37NWx6lOSUYGznu+4Yh3V+4f0dc6/7kt1XcO9iA5OAbJwTE05hyqLCAJCQksX76cNm3aWNfddtttdOvWjccff7zaAhIYGMiePXusywaDAb1eb122WCwEBgayZs0aAFJTU2nfvj1QPmT8s88+S0ZGBh999BGenrX7gLOzC1AUtcI6f39PDIb8Wh2nOuf+uwwLGgy9BpNjLKzXY1fGFjk0NMnBMUgOjsFRctBqNVX+8L7m66raoKpqheJxSfv27bFYLNUeuG/fvuzevRuj0UhxcTEpKSmEh/8xpatGo2Hy5MlkZGSgqirLly8nMjISgIULF1JQUMAHH3xQ6+LRUIqOH6Ng74/s9r6Zbjd1snc4QgjR4KpsgVgsFhRFuWrkXUVRajSpVEBAANOnTyc2NhaTyURMTAyhoaHExcUxbdo0QkJCmDdvHlOnTqWsrIywsDCmTJmC0WhkxYoVtGvXjjFjxliPt2HDhj+RZv1SFQXDpwmYWrbiB++buPv36WuFEKI5qbKA3HrrrSxfvpzJkydXWL9s2TJCQkJqdPBLfTwut3TpUuvfgwYNYtCgQRW2+/r6cvjw4Rod317ydu+k9NRv7LtpGEHe3vh4uto7JCGEaHBVFpDHH3+ciRMnsnXrVm655RYURWHfvn0UFBSwfPnyBgzRsSglJWR9thaXzl342hTAMGl9CCGaqSrvgXh6erJmzRrGjBlDSUkJJpOJCRMmsG7dOnx9fRsyRodSdOwoltxcLvYejEWFkC7N97MQQjRv1xwLy8XFhTvvvJM777yzoeJxeGZj+ayDhwpdcXO1cF3bVnaOSAgh7KPKAjJp0qQK/TacnJzw9vZm4MCB1T7C25SZjEZwcuKnc6Xc1Mm3Qfp+CCGEI6qygEycOLHCsqIoZGdn8/HHH5OTk8MDDzxg8+AckdloROPlTU5BGSFy/0MI0YxVWUCGDRtW6fro6GgmTZrUfAtIjpEi1/ION1JAhBDNWa2vv7Rq1apZj/lkNhrJUlvQzt9DHt8VQjRrtS4gqqrWqCNhU6QqCqYcI+fKnAm5Tp6+EkI0b1Vewrp48WKl6z7++GN69Ohh06AclSUvDywWLurcua2TFBAhRPNWZQHp06cPGo0GVS0flFCj0eDj48PAgQOZNWtWgwXoSExGIwD5upa0bd3SztEIIYR9VVlALs3TcTmz2UxycjIPPPCAdRTd5sScU94HpKSFJ14tZeZBIUTzds2OhJfk5uayatUqVqxYQVFR0VWP+DYX5t9bIK6tWzfrBwmEEAKqKSC//PILH374IRs3bqRt27aUlJSwfft2hx1i3dZMRiNmrQ5vf297hyKEEHZX5VNYDz74IBMnTsTZ2ZmPPvqIzz//nJYtWzbb4gFgys4m18kdva+7vUMRQgi7q7KAHD58mO7du3P99dfTsWNHgGZ/2aYkK4s8XUsCfKSACCFElQXk66+/5s477+Tzzz+nf//+TJs2jdLS0oaMzeGYc4zk69zRe7vZOxQhhLC7KguITqcjMjKSjz/+mM8++wy9Xk9paSlDhw5l5cqVDRmjQ1DNZsjPJ0/XEr2PFBAhhKhRT/SuXbsye/ZsvvnmG6ZMmcLq1attHZfDMV/MQYNKkasH3jKEiRBC1G4oEzc3N8aOHcv69etrtH9SUhKRkZEMHTqUFStWXLV9x44d1mlvZ8yYQWFhIQB5eXk8+OCD3HHHHUyYMAGDwVCbMG3iUidCjbcv2mZ+L0gIIaAOY2HVVEZGBvHx8SQkJJCYmMiqVatIS0uzbs/Ly2PmzJnEx8eTlJREcHAw8fHxALz55pv07t2bLVu2MGbMGObPn2+rMGvMnFNeQFq0lhF4hRACbFhAdu3aRZ8+ffD29sbd3Z1hw4aRnJxs3Z6enk6bNm3o2rUrABEREWzduhUov4EfHR0NQFRUFN988w0mk8lWodaIKbu8F7pnoN6ucQghhKOoUU/0usjMzMTf39+6rNfrSU1NtS536tSJCxcucPToUYKDg9myZQtZWVlXvVan0+Hh4YHRaCQgIKBG7+3n51Hpen//uvdhyczLpUTrQufrAv7Ucf4se753fZEcHIPk4Bgacw42KyCKolToN6KqaoVlLy8vFi5cyJw5c1AUhXvuuQdnZ+dKj6WqKlptzRtL2dkFKIpaYZ2/vycGQ34ts/hDzqlz5Onc8dFp/9Rx/ow/m4MjkBwcg+TgGBwlB61WU+UP72uxWQEJDAxkz5491mWDwYBe/8flH4vFQmBgoHVQxtTUVNq3bw+Ut1aysrIIDAzEbDZTWFiIt7d9hw8xG43k6VpygzzCK4QQgA3vgfTt25fdu3djNBopLi4mJSWF8PBw63aNRsPkyZPJyMhAVVWWL19OZGQkAAMHDiQxMRGAzZs307t37ypbJw1Fk3+RAueW+HrJI7xCCAE2LCABAQFMnz6d2NhYRo8eTVRUFKGhocTFxXHgwAG0Wi3z5s1j6tSpDB8+HC8vL6ZMmQLA448/zr59+xgxYgQJCQnMnTvXVmHWiFJaiq60GIunN061uJQmhBBNmc0uYQHWPh6XW7p0qfXvQYMGMWjQoKte5+3tzX/+8x9bhlYr5pwcAJx8fOwciRBCOA75OV0Dpuzyp8PcWre2cyRCCOE4pIDUQP6F8p7wHtIHRAghrKSA1EDe+QwA/NrVrB+KEEI0Bza9B9JUFBuysTi1oI2/l71DEUIIhyEFpAbMOUYKdC1p3aqFvUMRQgiHIZewakCbf5FSN090TvJxCSHEJfKNWA1VVXEpykPxtG9PeCGEcDRSQKqhFBfhbDHh5ONr71CEEMKhSAGpRt75TADc/KUPiBBCXE4KSDWyT18AwDPIv5o9hRCieZECUo3831sgvu2D7ByJEEI4Fikg1Sg2GFDQENBeOhEKIcTlpIBUw2zModDZHRcX+w4nL4QQjkYKSDW0+Rcpc5ce6EIIcSUpINVwLZY+IEIIURkZyuQaiorLaGkqRJE+IEIIcRVpgVxD5lkDOlWhhfQBEUKIq9i0gCQlJREZGcnQoUNZsWLFVdsPHTrE3XffzciRI/nb3/5GXl4eALm5ucTFxTFy5EhiYmI4cuSILcOskvFMeR8QL+kDIoQQV7FZAcnIyCA+Pp6EhAQSExNZtWoVaWlpFfaZP38+06ZNY+PGjXTu3Jn3338fgGXLltGtWzc2btzII488wrx582wV5jVd6oXuJ31AhBDiKjYrILt27aJPnz54e3vj7u7OsGHDSE5OrrCPoigUFhYCUFxcTIsWLa65vqEVG8qnsnUPkBaIEEJcyWY30TMzM/H3/+OLV6/Xk5qaWmGfmTNnMnnyZBYsWICbmxurV68GYPLkyYwdO5b+/ftTWFjIBx98YKswr8mSk4NF64STh6dd3l8IIRyZzQqIoihoNBrrsqqqFZZLSkqYNWsWy5cvJzQ0lGXLlvHss8/y7rvv8tJLLzFhwgRiY2P5+eefmT59Ops2baJly5Y1em8/P49K1/v7164QOOVfxOTuhV7vOP1AapuDI5IcHIPk4Bgacw42KyCBgYHs2bPHumwwGNDr9dbl48eP4+rqSmhoKABjx47lrbfeAmDbtm3W+x49e/bEz8+PkydPWvetTnZ2AYqiVljn7++JwZBf4/hLTRZcS/Kx+LSq1etsqbY5OCLJwTFIDo7BUXLQajVV/vC+5utsEAsAffv2Zffu3RiNRoqLi0lJSSE8PNy6vWPHjly4cIFffvkFKC8aISEhAAQHB7N161YA0tPTyczMpHPnzrYKtVKGi8V4mQvR+fg16PsKIURjYbMWSEBAANOnTyc2NhaTyURMTAyhoaHExcUxbdo0QkJCeOWVV3jiiSdQVRU/Pz8WLFgAwKuvvsrcuXNZunQpLi4uLFy4EE/Phm3mZWYX4GEuRid9QIQQolIaVVXV6ndrXOrjEtaX2w7QceXreI+bhP722+o7xDpxlObunyE5OAbJwTE4Sg4Odwmrscs/nwFAS3mEVwghKiUFpAolv/cB0fnKOFhCCFEZKSBVsFzMAUAnAykKIUSlpIBUwmRWcCrIxeLsipO7u73DEUIIhyTDuVciK7f8EV7VS+YBEaKhqKpKTo6BsrISoPpnezIztSiKYvvAbKjhc9Dg4tICHx//Ch2760oKSCUycy71AZF50IVoKAUFuWg0GgIC2qHRVH9xRKfTYjY37gLS0DmoqsLFi1kUFOTiWQ8T5cklrEpk5hTjaS7CTS99QIRoKMXFBXh6eteoeIi60Wi0eHr6UFxcUC/HkzNVCUNWPi0tJbhJJ0IhGoyiWHBykositubkpENRLPVyLCkglcjLKJ8HxNlXhjERoiHVx3V5cW31+RlLua/EpT4gztIHRIhm6fXXF3LgwH7MZhNnzpymU6cuAIwZM44RI0bW6BjvvfcfgoNvpH//gTV+X7PZzN13j2DQoNuYPv0Z6/r33/8vAFOm/M26bvPmJH7+eS+zZr0IwK5d3/Hxxx9QVFSMolgID49gypS/odXarp0gBeQKZosCl/qASAERolmaMeNZAM6fP8djj/2N5csTan2MqVMfqvVr/ve/ndx4Y3e2b9/Kww9Pq/Fkev/73y7i4xfx+uuL6dChI6WlJcyd+xzvv/9f4uIernUcNSUF5ArGvBI8TOWzIUonQiHEld5//78cOnSQzMwL3H33WDp16sy77/6b0tIS8vMLmDZtOgMGDGL+/Bfp2bMXPXv24vnnn6JLl+s4fvwYvr5+vPTSq3h5tbrq2Js2JREeHoGiqGzd+gVRUaNqFNNHH31AbOxkOnToCICrawtmzJjJb7+l12fqV5ECcoXyJ7AKwb0lWhcXe4cjRLO388B5vks9f9V6jQZqOhRs/9Ag+oUE1VtMZWWlfPLJGgBmz36GmTPn0LFjJ/bu/ZG33nqNAQMGVdg/Le0Ezz03l27dgpk162lSUrYQEzOuwj45OTns2fM9zz03FycnJ9auXVXjAnLixDEef/ypCuv0+gD0ett2RZCb6FfIyCnGy1yETm6gCyGqcNNNN1v/njPnJX75JY3ly9/j008/obi4+Kr9fXx86dYtGIAuXbqSl5d31T4pKZvp1euveHl5MWDAQE6eTOP48aMAld7HuHyWV41Gi4sdfvBKC+QKhovFdLAU4tq6YSewEkJUrl9I5a0He3YkdHV1tf796KNx3HJL+aWqXr3+yj/+Mfuq/a/8cq9sFo3Nmz8nO9tATEw0UD7E+oYNn/H008/j6enJ2bNnK+yfk2PE07N8uu3g4Bs5evQwnTt3sW4/deo3PvzwfebMmVf3RKshLZArZP7eApEnsIQQ1cnLy+X06d+YMuUh+vTpx7ff7qjT0CRHjx4hMzODdes+Z+3aJNauTWLRojdJSUmmqKiQW27pza5d35KTU/6AT0FBAdu2pdC7960AjB8fy7JlSzl9+hQARUVF/Otf8QQEBNZfspWQFsgVjIaLuFjKZCpbIUS1vLxaERU1ikmT7kGn03HLLX+lpKSk0stY17J580YiI6Nxdf3jqatbbulN+/YdSEnZwujRMUya9ABPPPEIABaLhZEjRxMW1g+APn368uCDj/DCC89hsShYLGYiIm7ngQfi6i/ZSth0RsKkpCSWLFmC2WzmvvvuY8KECRW2Hzp0iLlz52IymQgKCuKf//wnXl5eFBQU8MILL3Dy5EkA5s+fT/fu3Wv8vnWdkVBRVGYtWM8D6RsJjHsIr//rU+P3bAiOMnvZnyE5OAZHzOHChd8IDOxY4/1lLKy6u/KzdrgZCTMyMoiPjychIYHExERWrVpFWlpahX3mz5/PtGnT2LhxI507d+b9998H4JVXXiEoKIjExESefPJJXnzxRVuFWUFOfinupeWP8MolLCGEuDabXcLatWsXffr0wdu7fMTHYcOGkZyczN///nfrPoqiUFhY/oVdXFxMq1atUFWVlJQUtm3bBkB4eDhBQfX3+N21ZOYU4WX+vQ+IPIUlhBDXZLMWSGZmJv7+f8wnrtfrycjIqLDPzJkzmT17Nv3792fXrl2MGzeO7OxsXFxcSEhIYOzYscTGxmKx1M/AX9XJuFh+Ax2NBp23zAUihBDXYrMWiKIoFQbtuvyZZYCSkhJmzZrF8uXLCQ0NZdmyZTz77LO89NJLZGVl4enpyapVq9i5cyePPvqotUVSE1Vdy/P397zm6wpKLLSyFOLi64M+0DELSHU5NAaSg2NwtBwyM7XodLX7TVvb/R2RPXLQarX1cv5tVkACAwPZs2ePddlgMKDX663Lx48fx9XVldDQUADGjh3LW2+9hY+PDzqdjqioKAD69etHUVER2dnZ+PnV7LJSXW+ip5/LJYQStK18HO4GIzjmjc/akhwcgyPmoChKrW4oy030ulMUpcL5d7ib6H379mX37t0YjUaKi4tJSUkhPDzcur1jx45cuHCBX375BYBt27YREhKCi4sLffv2ZdOmTQDs27cPNzc3fHx8bBWq1aV7IDKIohBCVM9mLZCAgACmT59ObGwsJpOJmJgYQkNDiYuLY9q0aYSEhPDKK6/wxBNPoKoqfn5+LFiwACh/Omvu3LkkJCSg0+mIj4+36ZDEUH6JLTOnCLfSApkHRAghasCmHQmjo6OJjo6usG7p0qXWvwcOHMjAgVePla/X6/nPf/5jy9CuYraotLCUorWYpQUiRDNXH/OBXPLSS3N46KHH8PfXV7r9/vvHExTUhldeec26LikpkUOHDjBz5hzruh9//J5PPvmQt976NwAHDuxn6dIl5ObmYrFY6NWrN4888niFYVZsTXqi/85Zp2XunV3JWiTDuAvR3NXHfCCX/PTT3krHvoLyIUw8PDw4evQwWVkGWrf2r3S/Kx0/fpTZs5/l1Vdf58Ybu2M2m3n99Vd5/fVXef75F+oca21JAbmMS2H5CJnSiVAIUZWiokJef30hv/76C6qqMHHiA9x22xCOHz/KP//5Coqi4OrqyqxZL7J16xfk5Bh58snHWLLkfTw9Kz759PnnG+nd+1Y6depMUlJijYceWbHiI0aOvJMbbywfoUOn0/HII4/z0097qnll/ZICchlTjhGQmQiFsLe8XTvJ/e6ba+6j0Wiq/GV/La36h+PVt19dQ+ODD5bSvXsIc+bMo6CggIcemkz37jezatUKJk68n4EDI/j88w0cOnSQ++6bQmLiOt54Y/FVxcNkMvHll1+wZMl7ZGVl8fLLLxAbOxknJ6dqYzhx4hhDhgyrsM7T05OBAyPqnFddSAG5jNloRKPT4fT7EMlCCHGlPXt+wGw2sXHjegBKSor59ddfCAvrz2uvvcLu3d/Rr98A+vULv+Zxvv12B4GBgXTo0Il27TpgsVjYvXsn/fuHV+gz9wcVrbZ8vVarxcWl4e51VEUKyGXMRiM6Hx80Nn7iSwhxbV59+1XbSrBfHwoLL764gK5drwfAaMzGy6sVOp2O0NAe7Nz5LStXfsL33+/mqaeeq/I4mzdv5Pz5c9b5P0pKitm48TP69w/H09OLgoKK/XRycnKs83/ccEP5/B+33vrHgK/5+fm8/PJc5s//Jzpdw3y1yzflZUzGbLmBLoS4pltu+SuJiWsBMBgyiY0dR1aWgVmznubEiePceWcMU6b8jWPHymcTdHJyumo4pqwsAz/9tJeEhDXW+T/ee+9jvv9+NxcunCckJJSDBw9w7lz5JFKlpaUkJ2+yzv8xbtwE1q1bxdGjh4Hyy2GLF79hLWQNRVoglzEbjbh162bvMIQQDmzq1Id47bVXiI0di6IoPPbYdAIDg7jvviksXDif995bgouLq/VJrr59+/Pkk38nPv7fBAaWT/C0Zcsm+vcPp3Vrf2srqn37DoSF9WPjxvU8+OAjzJjxLLNnP4OiqJhMZURE3G6dI/3662/g+edf5I03FlFaWorFYqZ37//j4Ycfa9DPwqbzgdhLXYYyURWFEw9NxXd4JK3virF1iHXiiMNP1Jbk4BgcMQeZD6ThOPx8II2NarGgdXXFtZPMhS6EEDUhl7B+p3V25rr4xVCDR+iEEEJIAalA04A3n4QQorGTS1hCCIfRBG/JOpz6/IylgAghHIJO50JhYZ4UERtSVZXCwjx0Opd6OZ5csxFCOAQfH39ycgwUFFys0f5arRZFadxPYdkjB53OBR+fmg3aWO2x6uUoQgjxJzk56WjdOqjG+zvio8i11dhzkEtYQggh6kQKiBBCiDppkpewLo1YWdP1jYnk4BgkB8cgOdg3hiY5lIkQQgjbk0tYQggh6kQKiBBCiDqRAiKEEKJOpIAIIYSoEykgQggh6kQKiBBCiDqRAiKEEKJOpIAIIYSoEykgQggh6qTJF5CkpCQiIyMZOnQoK1assHc4dTJp0iRGjBjBqFGjGDVqFPv377d3SDVWUFBAVFQUZ86cAWDXrl1ER0czdOhQ4uPj7RxdzVyZw3PPPcfQoUOt5+PLL7+0c4TX9q9//YsRI0YwYsQIFi1aBDTO81BZHo3tXLz11ltERkYyYsQIli1bBjTOc2GlNmEXLlxQIyIi1JycHLWwsFCNjo5WT5w4Ye+wakVRFLV///6qyWSydyi1tm/fPjUqKkrt3r27evr0abW4uFgdOHCgeurUKdVkMqmTJ09Wv/76a3uHeU1X5qCqqhoVFaVmZGTYObKa2blzpzp27Fi1tLRULSsrU2NjY9WkpKRGdx4qyyMlJaVRnYvvv/9eHTdunGoymdTi4mI1IiJCPXLkSKM7F5dr0i2QXbt20adPH7y9vXF3d2fYsGEkJyfbO6xa+eWXXwCYPHkyI0eO5JNPPrFzRDW3evVqXnjhBfR6PQCpqal07NiR9u3bo9PpiI6OdvjzcWUOxcXFnDt3jueff57o6Gjefvtth57UyN/fn5kzZ+Li4oKzszPXXXcd6enpje48VJbHuXPnGtW5uPXWW/noo4/Q6XRkZ2djsVjIy8trdOfick26gGRmZuLv/8fMW3q9noyMDDtGVHt5eXmEhYXxzjvvsHz5cj799FN27txp77BqZP78+fTu3du63BjPx5U5ZGVl0adPHxYsWMDq1avZs2cPa9eutWOE13b99dfTo0cPANLT09myZQsajabRnYfK8hgwYECjOhcAzs7OvP3224wYMYKwsLBG+f+JyzXpAqIoChrNH8MUq6paYbkx6NmzJ4sWLcLT0xNfX19iYmLYsWOHvcOqk6ZwPtq3b88777yDXq/Hzc2NSZMmNYrzceLECSZPnswzzzxD+/btG+15uDyPLl26NMpzMW3aNHbv3s358+dJT09vtOcCmngBCQwMxGAwWJcNBoP1UkRjsWfPHnbv3m1dVlUVna5xTuPSFM7HsWPH+OKLL6zLjeF87N27l/vvv58ZM2Zw5513NtrzcGUeje1cnDx5kiNHjgDg5ubG0KFD+f777xvlubikSReQvn37snv3boxGI8XFxaSkpBAeHm7vsGolPz+fRYsWUVpaSkFBAevXr2fIkCH2DqtO/vKXv/Drr7/y22+/YbFY+Pzzzxvd+VBVlQULFpCbm4vJZGLVqlUOfT7Onz/Po48+ymuvvcaIESOAxnkeKsujsZ2LM2fOMHv2bMrKyigrK2Pbtm2MGzeu0Z2Lyzluua4HAQEBTJ8+ndjYWEwmEzExMYSGhto7rFqJiIhg//79jB49GkVRGD9+PD179rR3WHXi6urKq6++ymOPPUZpaSkDBw5k+PDh9g6rVoKDg3nwwQe59957MZvNDB06lKioKHuHVaX333+f0tJSXn31Veu6cePGNbrzUFUejelcDBw4kNTUVEaPHo2TkxNDhw5lxIgR+Pr6NqpzcTmZkVAIIUSdNOlLWEIIIWxHCogQQog6kQIihBCiTqSACCGEqBMpIEIIIepECohotl5++WXrKK4333wzw4YNsy6XlJTY/P0PHDjA4MGD/9QxZs+ezcGDB4HyUZsb0zhKovFr0v1AhLiW2bNnW/8ePHgwr732GiEhIXaMqPZ27drF2LFj7R2GaKakgAhRhZtvvpnbbruNo0eP8tprr+Hu7s78+fO5ePEiFouFSZMmERMTA8D27dtZsmQJJpOJFi1a8Oyzz1ba4TMhIYEPP/wQDw8PunXrVmHbkiVLSElJQVEU2rZtywsvvEBAQACTJk3ipptuYu/eveTk5DBq1CimTZtGfHw8mZmZPPXUU9b5MbZt28b7779PVlYWYWFhvPzyy2i1cqFB2IidhpEXwqFERESoqampFdZ169ZNXb9+vaqqqmoymdTIyEj14MGDqqqqal5ennrHHXeoP//8s/rrr7+qUVFRqtFoVFVVVY8fP67269dPLSwsrHC8w4cPq2FhYWpmZqaqqqo6Z84cNSIiQlVVVV2/fr36xBNPWOd9+fTTT9WpU6eqqqqqEydOVOPi4tSysjI1NzdXHTZsmLp9+/ar4p44caL68MMPq2azWS0qKlL79eun/vjjj/X+WQlxibRAhLiGS0O5p6enc+rUKZ5//nnrtpKSEg4fPoyqqmRmZnL//fdbt2k0Gk6dOkVwcLB13e7du2uAF24AAAHtSURBVOnXr591+O6xY8fy3XffAfDVV19x4MAB7r77bqB85OLi4mLra8eOHYuzszPOzs4MHz6c7777joiIiKvijYyMxMnJCTc3Nzp16kR2dnb9fRhCXEEKiBDX4O7uDoDFYsHT05MNGzZYt2VlZeHp6cnq1asJCwvjzTfftG47f/58paOqqpeNHOTk5GT9W1EUpk6dyvjx4wEoKysjNzfXuv3yUWZVVa3ystTl+2k0mgrvJ0R9k4ujQtRA586dadGihbWAnD9/nqioKA4ePEhYWBg7d+7k5MmTAOzYsYORI0de9SRXv3792LlzJxcuXABg/fr11m39+/dn7dq1FBQUAOVzZz/zzDPW7Rs3bkRRFHJzc9myZYv16S0nJyfMZrPtEhfiGqQFIkQNuLi48O9//5v58+fz3nvvYTabefzxx+nVqxcA8+bN48knn7TOSbFkyRJatmxZ4Rg33HADTz/9NPfddx8tW7asMDL0mDFjyMjI4J577kGj0RAUFFRh5NmSkhJiYmIoLCxk/PjxhIWFATBkyBCefvppXnzxRdt/CEJcQUbjFcLBTZo0iQkTJjSqYb5F8yCXsIQQQtSJtECEEELUibRAhBBC1IkUECGEEHUiBUQIIUSdSAERQghRJ1JAhBBC1IkUECGEEHXy/0IyrVeIMISbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "   rf = RandomForestClassifier(max_depth=max_depth, n_estimators=25, n_jobs=-1, random_state=42)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "    \n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.title('AUC plot for RF')\n",
    "plt.savefig(os.path.join('2-3-b-rf(Treedepth).png'), dpi=300, format='png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#Source: https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_tuned = RandomForestClassifier(n_estimators=100,random_state=42, max_depth=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_tuned = rfc_tuned.fit(X_train, y_train)\n",
    "rfc_tuned_pred = rfc_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from the default parameters for Random forests:\n",
      "Accuracy is  94.6969696969697\n",
      "[[329   8]\n",
      " [ 27 296]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.98      0.95       337\n",
      "           1       0.97      0.92      0.94       323\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       660\n",
      "   macro avg       0.95      0.95      0.95       660\n",
      "weighted avg       0.95      0.95      0.95       660\n",
      "\n",
      "\n",
      "\n",
      "Results from the tuned parameters for Random forests:\n",
      "Accuracy is  96.96969696969697\n",
      "[[330   7]\n",
      " [ 13 310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.98      0.97       337\n",
      "           1       0.98      0.96      0.97       323\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       660\n",
      "   macro avg       0.97      0.97      0.97       660\n",
      "weighted avg       0.97      0.97      0.97       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Results from the default parameters for Random forests:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,rfc_pred)*100)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,rfc_pred))\n",
    "print('\\n')\n",
    "print(\"Results from the tuned parameters for Random forests:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,rfc_tuned_pred)*100)\n",
    "print(confusion_matrix(y_test,rfc_tuned_pred))\n",
    "print(classification_report(y_test,rfc_tuned_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mlp = MLPClassifier(random_state=42)\n",
    "nn_mlp.fit(X_train, y_train)\n",
    "nn_mlp_pred = nn_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'max_iter': [2000],\n",
    "    'hidden_layer_sizes': [(57,57,57), (57,57),(57,30,10)], # (57,57,30,20,5)],\n",
    "    'activation': ['tanh', 'relu','logistic'],\n",
    "    'solver': ['sgd', 'adam','lbfgs'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'random_state': [42],\n",
    "    'batch_size': [70, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_iter': [2000], 'hidden_layer_sizes': [(57, 57, 57), (57, 57), (57, 30, 10)], 'activation': ['tanh', 'relu', 'logistic'], 'solver': ['sgd', 'adam', 'lbfgs'], 'alpha': [0.0001, 0.05], 'random_state': [42], 'batch_size': [70, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_mlp_tuned = GridSearchCV(nn_mlp, parameter_space, n_jobs=-1, cv=5, refit=True)\n",
    "nn_mlp_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.05, 'batch_size': 70, 'hidden_layer_sizes': (57, 57), 'max_iter': 2000, 'random_state': 42, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', nn_mlp_tuned.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.05, batch_size=70, beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(57, 57), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "Results from the default parameters for the neural network:\n",
      "Accuracy is  90.45454545454545\n",
      "[[308  29]\n",
      " [ 34 289]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.91      0.91       337\n",
      "           1       0.91      0.89      0.90       323\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       660\n",
      "   macro avg       0.90      0.90      0.90       660\n",
      "weighted avg       0.90      0.90      0.90       660\n",
      "\n",
      "\n",
      "\n",
      "Results from the tunned parameters for the neural network:\n",
      "Accuracy is  91.81818181818183\n",
      "[[314  23]\n",
      " [ 31 292]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.93      0.92       337\n",
      "           1       0.93      0.90      0.92       323\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       660\n",
      "   macro avg       0.92      0.92      0.92       660\n",
      "weighted avg       0.92      0.92      0.92       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_mlp_tuned1 = MLPClassifier(activation = nn_mlp_tuned.best_params_['activation'],\n",
    "                       alpha = nn_mlp_tuned.best_params_['alpha'], \n",
    "#                        learning_rate= nn_mlp_tuned.best_params_['learning_rate'], \n",
    "                       solver = nn_mlp_tuned.best_params_['solver'], \n",
    "                       random_state = nn_mlp_tuned.best_params_['random_state'], \n",
    "                       hidden_layer_sizes = nn_mlp_tuned.best_params_['hidden_layer_sizes'],\n",
    "                       batch_size = nn_mlp_tuned.best_params_['batch_size'],\n",
    "                       max_iter = nn_mlp_tuned.best_params_['max_iter'],\n",
    "#                        early_stopping = True,\n",
    "                             )\n",
    "print(nn_mlp_tuned1)\n",
    "\n",
    "nn_mlp_tuned1.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, nn_mlp_tuned1.predict(X_test)\n",
    "\n",
    "print(\"Results from the default parameters for the neural network:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,nn_mlp_pred)*100)\n",
    "print(confusion_matrix(y_test,nn_mlp_pred))\n",
    "print(classification_report(y_test,nn_mlp_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Results from the tunned parameters for the neural network:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_true,y_pred)*100)\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ec40ae7748>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn_mlp_tuned1.loss_curve_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Varying the split of the training-test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "def cross_validate_model(X, y, clf, n_splits):\n",
    "    #define 10-fold cross validation test harness\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True)\n",
    "    results = []\n",
    "    count = 1\n",
    "    for _ in range(20):\n",
    "        for train, test in kfold.split(X, y):\n",
    "            count += 1\n",
    "            \n",
    "            \n",
    "            t0 = time.time()\n",
    "            model = clf.fit(X[train], y[train])\n",
    "            t1 = time.time()\n",
    "            y_pred = model.predict(X[test])\n",
    "            t2 = time.time()\n",
    "\n",
    "            classification_time = round(t2-t1, 3) # Classification time rounded to 3 decimal in seconds\n",
    "            training_time = round(t1-t0, 3) # Classification time rounded to 3 decimal in seconds\n",
    "            precision,recall,fscore,support = score( y[test],y_pred,average='macro')\n",
    "            accuracy = accuracy_score(y[test],y_pred)\n",
    "            results.append([accuracy, precision, recall, fscore, support, training_time, classification_time, n_splits])\n",
    "    \n",
    "    result_data = pd.DataFrame(results)\n",
    "    result_data.columns = [\"accuracy\", \"precision\", \"recall\", \"fscore\", \"support\", \"training_time\", \"classification_time\", \"num_folds\"]\n",
    "    \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Run Kfold for 4,5,6,7 folds 20 times each\n",
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "data = pd.DataFrame()\n",
    "for n_folds in [4,5,6,7]:\n",
    "    knn_result = cross_validate_model(X.values, y.values, knn, n_folds)\n",
    "    data = pd.concat([data, knn_result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fscore</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">classification_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_folds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.745864</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>0.808710</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>0.753512</td>\n",
       "      <td>0.018404</td>\n",
       "      <td>0.735450</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.078737</td>\n",
       "      <td>0.005182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.748864</td>\n",
       "      <td>0.024771</td>\n",
       "      <td>0.811162</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>0.756567</td>\n",
       "      <td>0.019308</td>\n",
       "      <td>0.738834</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.065730</td>\n",
       "      <td>0.005216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.749138</td>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.810598</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.756590</td>\n",
       "      <td>0.019838</td>\n",
       "      <td>0.738984</td>\n",
       "      <td>0.024429</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.056383</td>\n",
       "      <td>0.003016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.749615</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.811470</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.757170</td>\n",
       "      <td>0.019821</td>\n",
       "      <td>0.739602</td>\n",
       "      <td>0.025480</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.050071</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy           precision              recall            \\\n",
       "               mean       std      mean       std      mean       std   \n",
       "num_folds                                                               \n",
       "4          0.745864  0.023114  0.808710  0.013763  0.753512  0.018404   \n",
       "5          0.748864  0.024771  0.811162  0.017760  0.756567  0.019308   \n",
       "6          0.749138  0.022607  0.810598  0.014659  0.756590  0.019838   \n",
       "7          0.749615  0.024383  0.811470  0.017244  0.757170  0.019821   \n",
       "\n",
       "             fscore           training_time           classification_time  \\\n",
       "               mean       std          mean       std                mean   \n",
       "num_folds                                                                   \n",
       "4          0.735450  0.024561      0.003663  0.000655            0.078737   \n",
       "5          0.738834  0.025422      0.003870  0.000646            0.065730   \n",
       "6          0.738984  0.024429      0.004100  0.000640            0.056383   \n",
       "7          0.739602  0.025480      0.004179  0.000732            0.050071   \n",
       "\n",
       "                     \n",
       "                std  \n",
       "num_folds            \n",
       "4          0.005182  \n",
       "5          0.005216  \n",
       "6          0.003016  \n",
       "7          0.002184  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = {\n",
    "    \"accuracy\": ['mean', 'std'], \n",
    "    \"precision\": ['mean', 'std'], \n",
    "    \"recall\": ['mean', 'std'], \n",
    "    \"fscore\": ['mean', 'std'], \n",
    "#     \"support\": ['mean', 'std'], \n",
    "    \"training_time\": ['mean', 'std'], \n",
    "    \"classification_time\": ['mean', 'std']\n",
    "}\n",
    "data.groupby(['num_folds']).agg(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Run Kfold for 4,5,6,7 folds 20 times each\n",
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "svm = SVC(kernel='rbf', gamma=0.01, C=10,random_state=42)\n",
    "data = pd.DataFrame()\n",
    "for n_folds in [4,5,6,7]:\n",
    "    knn_result = cross_validate_model(X.values, y.values, svm, n_folds)\n",
    "    data = pd.concat([data, knn_result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fscore</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">classification_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_folds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.904977</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>0.905068</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.010072</td>\n",
       "      <td>0.904802</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>0.136550</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.906591</td>\n",
       "      <td>0.013718</td>\n",
       "      <td>0.906716</td>\n",
       "      <td>0.013808</td>\n",
       "      <td>0.907089</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>0.906390</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.154630</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.024990</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.908980</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.909205</td>\n",
       "      <td>0.013704</td>\n",
       "      <td>0.909547</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.908782</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.908477</td>\n",
       "      <td>0.015045</td>\n",
       "      <td>0.908656</td>\n",
       "      <td>0.014887</td>\n",
       "      <td>0.909214</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>0.908318</td>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.176264</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.018586</td>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy           precision              recall            \\\n",
       "               mean       std      mean       std      mean       std   \n",
       "num_folds                                                               \n",
       "4          0.904977  0.009886  0.905068  0.009814  0.905459  0.010072   \n",
       "5          0.906591  0.013718  0.906716  0.013808  0.907089  0.013772   \n",
       "6          0.908980  0.013963  0.909205  0.013704  0.909547  0.013829   \n",
       "7          0.908477  0.015045  0.908656  0.014887  0.909214  0.015080   \n",
       "\n",
       "             fscore           training_time           classification_time  \\\n",
       "               mean       std          mean       std                mean   \n",
       "num_folds                                                                   \n",
       "4          0.904802  0.009929      0.136550  0.007715            0.029375   \n",
       "5          0.906390  0.013799      0.154630  0.008387            0.024990   \n",
       "6          0.908782  0.013958      0.166458  0.008687            0.021308   \n",
       "7          0.908318  0.015047      0.176264  0.010253            0.018586   \n",
       "\n",
       "                     \n",
       "                std  \n",
       "num_folds            \n",
       "4          0.001435  \n",
       "5          0.001667  \n",
       "6          0.001454  \n",
       "7          0.001541  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = {\n",
    "    \"accuracy\": ['mean', 'std'], \n",
    "    \"precision\": ['mean', 'std'], \n",
    "    \"recall\": ['mean', 'std'], \n",
    "    \"fscore\": ['mean', 'std'], \n",
    "#     \"support\": ['mean', 'std'], \n",
    "    \"training_time\": ['mean', 'std'], \n",
    "    \"classification_time\": ['mean', 'std']\n",
    "}\n",
    "data.groupby(['num_folds']).agg(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Run Kfold for 4,5,6,7 folds 20 times each\n",
    "**DEFAULT PARAMETERS** #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "data = pd.DataFrame()\n",
    "for n_folds in [4,5,6,7]:\n",
    "    knn_result = cross_validate_model(X.values, y.values, rfc, n_folds)\n",
    "    data = pd.concat([data, knn_result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third classifier: Results from random forests(default parameters)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fscore</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">classification_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_folds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.931705</td>\n",
       "      <td>0.011215</td>\n",
       "      <td>0.933171</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>0.932839</td>\n",
       "      <td>0.011263</td>\n",
       "      <td>0.931581</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.935500</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.936539</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>0.936623</td>\n",
       "      <td>0.011228</td>\n",
       "      <td>0.935387</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>0.019870</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.933363</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.934647</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.934581</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.933234</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>0.020475</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.935523</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.936697</td>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.936593</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.935404</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy           precision              recall            \\\n",
       "               mean       std      mean       std      mean       std   \n",
       "num_folds                                                               \n",
       "4          0.931705  0.011215  0.933171  0.010612  0.932839  0.011263   \n",
       "5          0.935500  0.011552  0.936539  0.011329  0.936623  0.011228   \n",
       "6          0.933363  0.014262  0.934647  0.013498  0.934581  0.013813   \n",
       "7          0.935523  0.015066  0.936697  0.014821  0.936593  0.014565   \n",
       "\n",
       "             fscore           training_time           classification_time  \\\n",
       "               mean       std          mean       std                mean   \n",
       "num_folds                                                                   \n",
       "4          0.931581  0.011305      0.020400  0.006153            0.001738   \n",
       "5          0.935387  0.011577      0.019870  0.001529            0.001550   \n",
       "6          0.933234  0.014311      0.020475  0.001572            0.001467   \n",
       "7          0.935404  0.015075      0.020900  0.001495            0.001421   \n",
       "\n",
       "                     \n",
       "                std  \n",
       "num_folds            \n",
       "4          0.000545  \n",
       "5          0.000557  \n",
       "6          0.000517  \n",
       "7          0.000537  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = {\n",
    "    \"accuracy\": ['mean', 'std'], \n",
    "    \"precision\": ['mean', 'std'], \n",
    "    \"recall\": ['mean', 'std'], \n",
    "    \"fscore\": ['mean', 'std'], \n",
    "#     \"support\": ['mean', 'std'], \n",
    "    \"training_time\": ['mean', 'std'], \n",
    "    \"classification_time\": ['mean', 'std']\n",
    "}\n",
    "print(\"Third classifier: Results from random forests(default parameters)\")\n",
    "data.groupby(['num_folds']).agg(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier Run Kfold for 4,5,6,7 folds 20 times each\n",
    "**DEFAULT PARAMETERS** #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "nn_mlp = MLPClassifier(random_state=42)\n",
    "data = pd.DataFrame()\n",
    "for n_folds in [4,5,6,7]:\n",
    "    knn_result = cross_validate_model(X.values, y.values, nn_mlp, n_folds)\n",
    "    data = pd.concat([data, knn_result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third classifier: Results from random forests(default parameters)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fscore</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">classification_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_folds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.904023</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.904137</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.904522</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.011265</td>\n",
       "      <td>1.019775</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.904318</td>\n",
       "      <td>0.013531</td>\n",
       "      <td>0.904469</td>\n",
       "      <td>0.013608</td>\n",
       "      <td>0.904825</td>\n",
       "      <td>0.013506</td>\n",
       "      <td>0.904115</td>\n",
       "      <td>0.013595</td>\n",
       "      <td>1.052240</td>\n",
       "      <td>0.089332</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.908957</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.909144</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.909591</td>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.908772</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>1.225083</td>\n",
       "      <td>0.105306</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.908365</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.908520</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>0.909037</td>\n",
       "      <td>0.014826</td>\n",
       "      <td>0.908198</td>\n",
       "      <td>0.014704</td>\n",
       "      <td>1.099529</td>\n",
       "      <td>0.058040</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy           precision              recall            \\\n",
       "               mean       std      mean       std      mean       std   \n",
       "num_folds                                                               \n",
       "4          0.904023  0.011207  0.904137  0.011126  0.904522  0.011414   \n",
       "5          0.904318  0.013531  0.904469  0.013608  0.904825  0.013506   \n",
       "6          0.908957  0.014906  0.909144  0.014712  0.909591  0.014857   \n",
       "7          0.908365  0.014705  0.908520  0.014453  0.909037  0.014826   \n",
       "\n",
       "             fscore           training_time           classification_time  \\\n",
       "               mean       std          mean       std                mean   \n",
       "num_folds                                                                   \n",
       "4          0.903846  0.011265      1.019775  0.035731            0.000675   \n",
       "5          0.904115  0.013595      1.052240  0.089332            0.000690   \n",
       "6          0.908772  0.014893      1.225083  0.105306            0.000642   \n",
       "7          0.908198  0.014704      1.099529  0.058040            0.000507   \n",
       "\n",
       "                     \n",
       "                std  \n",
       "num_folds            \n",
       "4          0.000471  \n",
       "5          0.000563  \n",
       "6          0.000994  \n",
       "7          0.000530  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = {\n",
    "    \"accuracy\": ['mean', 'std'], \n",
    "    \"precision\": ['mean', 'std'], \n",
    "    \"recall\": ['mean', 'std'], \n",
    "    \"fscore\": ['mean', 'std'], \n",
    "#     \"support\": ['mean', 'std'], \n",
    "    \"training_time\": ['mean', 'std'], \n",
    "    \"classification_time\": ['mean', 'std']\n",
    "}\n",
    "print(\"Third classifier: Results from random forests(default parameters)\")\n",
    "data.groupby(['num_folds']).agg(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Run Kfold for 4,5,6,7 folds 20 times each\n",
    "**TUNED PARAMETERS** #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "rfc_tuned = RandomForestClassifier(n_estimators=100,random_state=42, max_depth=13)\n",
    "data = pd.DataFrame()\n",
    "for n_folds in [4,5,6,7]:\n",
    "    knn_result = cross_validate_model(X.values, y.values, rfc_tuned, n_folds)\n",
    "    data = pd.concat([data, knn_result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fifth classifier: Random Forest (tuned paramters)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fscore</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">classification_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_folds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965545</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.965535</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.965968</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.965475</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.182337</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>0.001267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.966136</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.966057</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.966612</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>0.966059</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.190760</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.966484</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.966539</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.197417</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.001294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.966773</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.966706</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.967227</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>0.201936</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.009707</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy           precision              recall            \\\n",
       "               mean       std      mean       std      mean       std   \n",
       "num_folds                                                               \n",
       "4          0.965545  0.006271  0.965535  0.006281  0.965968  0.006104   \n",
       "5          0.966136  0.008737  0.966057  0.008878  0.966612  0.008444   \n",
       "6          0.966615  0.008104  0.966484  0.008228  0.967125  0.007939   \n",
       "7          0.966773  0.009351  0.966706  0.009329  0.967227  0.009200   \n",
       "\n",
       "             fscore           training_time           classification_time  \\\n",
       "               mean       std          mean       std                mean   \n",
       "num_folds                                                                   \n",
       "4          0.965475  0.006288      0.182337  0.005960            0.012375   \n",
       "5          0.966059  0.008767      0.190760  0.005079            0.010990   \n",
       "6          0.966539  0.008116      0.197417  0.007613            0.010150   \n",
       "7          0.966699  0.009364      0.201936  0.006731            0.009707   \n",
       "\n",
       "                     \n",
       "                std  \n",
       "num_folds            \n",
       "4          0.001267  \n",
       "5          0.001185  \n",
       "6          0.001294  \n",
       "7          0.001333  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = {\n",
    "    \"accuracy\": ['mean', 'std'], \n",
    "    \"precision\": ['mean', 'std'], \n",
    "    \"recall\": ['mean', 'std'], \n",
    "    \"fscore\": ['mean', 'std'], \n",
    "#     \"support\": ['mean', 'std'], \n",
    "    \"training_time\": ['mean', 'std'], \n",
    "    \"classification_time\": ['mean', 'std']\n",
    "}\n",
    "print(\"Fifth classifier: Random Forest (tuned paramters)\")\n",
    "data.groupby(['num_folds']).agg(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier Run Kfold for 4,5,6,7 folds 20 times each\n",
    "**Tuned PARAMETERS** #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "nn_mlp_tuned2 = MLPClassifier(activation = nn_mlp_tuned.best_params_['activation'],\n",
    "                       alpha = nn_mlp_tuned.best_params_['alpha'], \n",
    "#                        learning_rate= nn_mlp_tuned.best_params_['learning_rate'], \n",
    "                       solver = nn_mlp_tuned.best_params_['solver'], \n",
    "                       random_state = nn_mlp_tuned.best_params_['random_state'], \n",
    "                       hidden_layer_sizes = nn_mlp_tuned.best_params_['hidden_layer_sizes'],\n",
    "                       batch_size = nn_mlp_tuned.best_params_['batch_size'],\n",
    "                       max_iter = nn_mlp_tuned.best_params_['max_iter'],\n",
    "#                        early_stopping = True,\n",
    "                             )\n",
    "data = pd.DataFrame()\n",
    "for n_folds in [4,5,6,7]:\n",
    "    knn_result = cross_validate_model(X.values, y.values, nn_mlp_tuned2, n_folds)\n",
    "    data = pd.concat([data, knn_result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sixth classifier: Neural Network (tuned paramter)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fscore</th>\n",
       "      <th colspan=\"2\" halign=\"left\">training_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">classification_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_folds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.915114</td>\n",
       "      <td>0.008754</td>\n",
       "      <td>0.915302</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.915638</td>\n",
       "      <td>0.008846</td>\n",
       "      <td>0.914955</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>2.323025</td>\n",
       "      <td>0.164931</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.918273</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>0.918448</td>\n",
       "      <td>0.012669</td>\n",
       "      <td>0.918779</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.918091</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>2.863520</td>\n",
       "      <td>0.394073</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.920320</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.920475</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>0.920848</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.920143</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>2.935850</td>\n",
       "      <td>0.239638</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.919751</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.919835</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.920329</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.919597</td>\n",
       "      <td>0.013616</td>\n",
       "      <td>2.773336</td>\n",
       "      <td>0.196689</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy           precision              recall            \\\n",
       "               mean       std      mean       std      mean       std   \n",
       "num_folds                                                               \n",
       "4          0.915114  0.008754  0.915302  0.008598  0.915638  0.008846   \n",
       "5          0.918273  0.012544  0.918448  0.012669  0.918779  0.012448   \n",
       "6          0.920320  0.013751  0.920475  0.013628  0.920848  0.013428   \n",
       "7          0.919751  0.013632  0.919835  0.013544  0.920329  0.013639   \n",
       "\n",
       "             fscore           training_time           classification_time  \\\n",
       "               mean       std          mean       std                mean   \n",
       "num_folds                                                                   \n",
       "4          0.914955  0.008798      2.323025  0.164931            0.000800   \n",
       "5          0.918091  0.012619      2.863520  0.394073            0.000610   \n",
       "6          0.920143  0.013758      2.935850  0.239638            0.000542   \n",
       "7          0.919597  0.013616      2.773336  0.196689            0.000564   \n",
       "\n",
       "                     \n",
       "                std  \n",
       "num_folds            \n",
       "4          0.000403  \n",
       "5          0.000510  \n",
       "6          0.000517  \n",
       "7          0.000526  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = {\n",
    "    \"accuracy\": ['mean', 'std'], \n",
    "    \"precision\": ['mean', 'std'], \n",
    "    \"recall\": ['mean', 'std'], \n",
    "    \"fscore\": ['mean', 'std'], \n",
    "#     \"support\": ['mean', 'std'], \n",
    "    \"training_time\": ['mean', 'std'], \n",
    "    \"classification_time\": ['mean', 'std']\n",
    "}\n",
    "print(\"Sixth classifier: Neural Network (tuned paramter)\")\n",
    "data.groupby(['num_folds']).agg(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
